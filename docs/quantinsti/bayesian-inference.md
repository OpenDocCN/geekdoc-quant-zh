# 贝叶斯推理的基础

> 原文：<https://blog.quantinsti.com/bayesian-inference/>

由 Vivek Krishnamoorthy

这篇关于贝叶斯推理的文章是关于贝叶斯统计和定量金融中使用的方法的系列文章的第二篇。

在我之前的[帖子](https://blog.quantinsti.com/introduction-to-bayesian-statistics-in-finance)中，我从容不迫地介绍了贝叶斯统计，同时区分了频繁主义者和贝叶斯世界观。我详述了他们的每一种基本哲学是如何影响他们对各种概率现象的分析的。然后，我讨论了贝叶斯定理，并用一些例子来帮助奠定贝叶斯统计的基础。

## **本帖意图**

我在这里的目的是通过关注频率统计和贝叶斯统计所采用的方法来帮助加深对统计分析的理解。在我的下一篇文章中，我有意识地选择使用 Python 来解决编程和模拟方面的问题。

我现在用一个简单的抛硬币的例子来说明前面讨论的观点，这个例子摘自《贝叶斯计量经济学导论(第二版)》。

### 例子:一个重复的掷硬币实验

假设我们对估计一个公平性未知的硬币的偏差感兴趣。我们将θ(希腊字母“theta”)定义为投掷硬币后得到正面的概率。 θ是我们要估计的未知参数。我们打算通过检查多次投掷硬币的结果来做到这一点。让我们用随机变量 Y 的实现来表示 Y(代表掷硬币的结果)。如果掷硬币的结果是正面，让 **Y=1** ，如果掷硬币的结果是反面，让 **Y=0** 。本质上，我们将 1 分配给正面，0 分配给反面。

**p(y = 1 |θ)=θ；p(y = 0 |θ)= 1-θ**

基于我们上面的设置，Y 可以被建模为[伯努利分布](https://en.wikipedia.org/wiki/Bernoulli_distribution),我们将其表示为

**Y∞伯努利(θ)**

在继续我们对未知参数 **θ** 的估计之前，我现在通过频率主义者和贝叶斯的透镜简要地观察我们的实验设置。

## **实验设置的两种观点**

在经典统计学(即频率主义方法)中，我们的参数 **θ** 是一个固定但未知的值，位于 **0** 和 **1** 之间。我们收集的数据是一个循环实验的一个实现(即重复这个**N**-折腾实验比如说 **N** 次)。最大似然法等经典估计技术用于得出θ̄̂(称为“theta hat”)，即未知参数 **θ** 的估计值。在统计学中，我们通常用参数的名称来表示估计值。我将在下一节详述这个观点。为了重申之前所说的，我们观察到在频率主义者的宇宙中，参数是固定的，但是数据是变化的。

贝叶斯统计是完全不同的。此处，参数θ被视为随机变量，因为其值存在不确定性。因此，将我们的参数视为随机变量是有意义的，它将具有相关的[概率分布](https://blog.quantinsti.com/statistics-probability-distribution/)。为了应用贝叶斯推理，我们将注意力转向概率论的一个基本定律，我们以前见过的[贝叶斯定理](https://en.wikipedia.org/wiki/Bayes%27_theorem)。

我使用贝叶斯定理的数学形式作为与贝叶斯推理建立联系的方式。

![Formula for Bayes' Theorem](img/8f5a53a135560d7bad27c42d629dd889.png) ……..![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor")①

重复一下我在之前的帖子中说过的，这个定理之所以如此方便，是因为它允许我们**反演一个条件概率**。因此，如果我们观察一种现象并收集关于它的数据或证据，该定理有助于我们分析性地定义给定证据的不同可能原因的*条件概率。*

现在让我们通过使用我们之前定义的符号将它应用到我们的例子中。我标上 **A = θ** 和 **B = y** 。在贝叶斯统计领域，这些术语中的每一个都有专门的名称，我将在下面详细说明并在以后使用。[①](#one)可以改写为:

![Bayes' Theorem revisited](img/5c4dbf6fad82f18e8ee97809a9b366a1.png) ……..![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor") (2)

其中:

**P(θ)** 是**的先验概率**。在观察证据 **Y** 之前，我们表达对原因 **θ** 的信念。在我们的例子中，先验将量化我们对硬币公平性的先验信念(这里我们可以从假设它是一个无偏的硬币开始，所以θ = 1/2)。 **P(Y|θ)** 是**的可能性**。这里是真正的行动发生的地方。这是假设原因下观察到的样本或证据的概率。让我们不失一般性地假设我们在 8 次掷硬币中获得 5 个正面。假设硬币如上所述是无偏的，假设θ = 1/2，可能性将是在 8 次投掷中观察到 5 个头的概率。 **P(θ|Y)** 是**后验概率**。这是观察到证据 y 后潜在原因θ的概率。在这里，我们使用贝叶斯定理，在观察到 8 次投掷中有 5 次投掷后，计算我们对硬币偏差的更新或后验置信。 **P(Y)** 是数据或证据的**概率。我们有时也称之为边际可能性。这是通过对所有可能的θ值取证据的似然函数的加权和(或积分)而得到的。在我们的例子中，我们将计算所有关于θ的可能信念在 8 次抛硬币中 5 次正面朝上的概率。该术语用于标准化后验概率。因为它独立于待估计的参数θ，所以从数学上来说，将后验概率表示为:**

**p(θ| y)√p(y |θ)×p(θ)**……。![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor")③

[(3)](#three) **是贝叶斯统计**中最重要的表达式，值得重复。为了清楚起见，我解释一下我先前说过的话。假设我们只知道 **P(Y|θ)** 和先验 **P(θ** ),贝叶斯推理允许我们改变条件概率，即使用先验概率和似然函数来提供后验概率的连接，即 **P(θ|Y)** 。我发现把 [(3)](#three) 看做是有帮助的:

**后验概率∝似然×先验概率**…………![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor") (4)

实验目的是根据 **n** 次独立掷硬币的结果，得到未知参数 **θ** 的估计值。掷硬币产生样本或数据 y = (y1，y2，…，yn)，其中 yi 是基于第**次**次掷硬币的结果的 1 或 0。

我现在展示频率主义者和贝叶斯方法来实现这个目标。如果你对背后的数学不感兴趣，请随意粗略浏览我在这里提到的推导。你仍然可以发展足够的直觉，并在实践中学习使用贝叶斯技术。

## **估算** θ: **频率主义者方法**

我们使用最大似然估计(MLE)方法计算联合概率函数。一次抛硬币的结果概率可以优雅地表示为:

![The Frequentist approach equation](img/6345b9dbf71485086554ca7a5d5d75f3.png)

对于给定的值 *θ* ，n 次独立掷硬币结果的联合概率是每个单独结果的概率的乘积:

![modification of frequentist approach question](img/d58e44c82052e23c14cbae80540a8a76.png) ……。![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor") (5)

正如我们在 [(4)](#four) 中看到的，在给定我们实验观察值的情况下，计算出的表达式是未知参数θ的函数。θ的函数称为似然函数，在文献中通常称为:

![Frequentist approach 1](img/6de55a26fcd980bb84dff290078d4c9c.png) ………..![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor") (6)

运筹学

![Frequentist approach 2](img/9cc7cce477bc13cc0b4905d62aebd03c.png)………………![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor")(7)

我们希望计算最有可能产生观察到的一组结果的 *θ* 的值。这被称为*最大似然估计*，θ̄̂(‘theta hat’)。为了解析计算，我们取 [(6)](#six) 关于参数的一阶导数，并将其设置为零。谨慎的做法是，也取二阶导数，并检查其值在θ = θ̄̂时的符号，以确保估计值确实是最大值。我们通常采用似然函数的对数，因为它大大简化了最大似然估计θ̄̂的确定。因此，文献中充满了对数似然函数及其解，这并不奇怪。

## **估算θ:贝叶斯方法**

我现在改变我们到目前为止使用的符号，使它们在数学上更加精确。我将在本系列中使用这些符号。这种改变的原因是为了让我们能够恰当地给每个术语赋予符号，以提醒我们它们的随机性。θ、Y 等的值存在不确定性。，因此，我们将它们视为随机变量，并给它们分配相应的概率分布，如下所示。

## **密度和分布函数的符号**

*   **【π(⋅】**(希腊字母‘pi’)表示**先验**(这与θ有关)**表示我们试图估计的参数的后验密度函数。**
*   ****f(⋅)** 表示连续随机变量的概率密度函数(pdf)和 p(。)即离散随机变量的概率质量函数(pmf)。然而，为了简单起见，我使用 **f(⋅)** 而不管随机变量 **Y** 是连续的还是离散的。**
*   **联合密度函数将继续表示为 **L(θ|⋅)** 。表示似然函数，它是样本值的联合密度，通常是我们数据中样本值的 pdf/PMF 的乘积。**

**记住 ***θ*** 是我们试图估计的参数。**

**[(2)](#two)[(3)](#three)可以改写为**

****(θ| y)=[∞f(y)**……![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor")(8)**

****π(μ| y)√f(y |μ)×π(μ)**…………。![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor") (9)**

**换句话说，**后验分布函数与似然函数乘以先验分布函数**成比例。我将你的注意力重新吸引到 [(4)](#four) 上，并以与我们的新符号一致的方式呈现出来。**

****后验 PDF ∝似然×先验 PDF**…………![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor")(十)**

**我现在用早先在 [(7)](#seven) 中定义的似然函数 L(θ|Y)重写 [(8)](#eight) 和 [(9)](#nine) 。**

**![modification of bayesian theorem](img/a00d8946c980e8698d2f158b5f45cac8.png) ……… ![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor") (11)**

**![modification of bayes theorem](img/7249fd9c5adf9c91cd89fb1eef458448.png) ………..![Anchor](img/4765334125b448ec4c4bdf8285a1da72.png "Anchor") (12)**

**[(11)](#eleven) 的分母是证据或数据的概率分布。我重申我之前在检查 [(3)](#three) 时提到的:考虑后验密度的一个有用的方法是使用比例方法，如 [(12)](#twelve) 所示。这样我们就不需要担心 [(11)](#eleven) 的 RHS 上的 f(y)项了。**

**对于你们当中对数学好奇的人来说，我现在带你们进入一个不必要的兔子洞来解释它。也许，在我们旅程的晚些时候，我会写一个单独的帖子来思考这些细枝末节。**

**在 [(11)](#eleven) ， **f(y)** 是使后验分布成为积分为 1 的适当密度函数的比例常数。当我们更仔细地检查它时，我们看到，事实上，这是随机变量 **Y** 的无条件(边际)分布。我们可以通过对参数 **θ** 的所有可能值进行积分来分析确定它。由于我们正在对 **θ** 进行积分，我们发现 **f(y)** 不依赖于 **θ** 。**

**![Integral for estimating theta](img/2f297975d9ea87931a5fae943708bcb3.png)**

**运筹学**

**![Second equation for bayesian inference](img/e9471f71d5b5ce5911cb24d8ef326b79.png)**

**[(11)](#eleven)[(12)](#twelve)代表贝叶斯定理的**连续版本。****

**后验分布是贝叶斯统计和推断的核心，因为它将参数 **θ** 的所有更新信息混合在一个表达式中。这包括在观察值被检查之前关于 **θ** 的信息，这是通过先验分布捕获的。观测值中包含的信息是通过似然函数获取的。**

**我们可以把 [(11)](#eleven) 看作是更新信息的一种方法，这一思想通过先验-后验命名法得到了进一步的例证。**

*   ****θ** 、 **π(θ)** 的先验分布代表了在记录观测值 **y** 之前关于其可能值的可用信息。**
*   **然后基于观测值 **y** 确定 **θ** 的似然函数 **L(θ|y)** 。**
*   ****θ** ， **π(θ|y)** 的后验分布总结了记录并合并观测值 **y** 后所有关于未知参数θ的可用信息。**

****θ的贝叶斯估计将是先验估计和最大似然估计的加权平均值，θ̄̂** 。随着观测值 **n** 的数量增加并趋近于无穷大，先验估计的权重趋近于零，最大似然估计的权重趋近于一。这意味着贝叶斯估计和频率估计会随着样本量的增加而收敛。**

**澄清一下，在经典或频率主义者的设定中，参数 **θ** 的通常估计量是最大似然估计量θ̄̂。在这里，先验被隐含地视为一个常数。**

## ****总结****

**我在这篇文章中致力于推导贝叶斯统计的基本结果，即。 [(10)](#ten) 。这个表达式的本质是通过结合从两个来源获得的知识来表示不确定性，这两个来源是观察和先前的信念。在这样做的时候，我介绍了先验分布、似然函数和后验分布的概念，以及频率主义者和贝叶斯方法的比较。在我的下一篇文章中，我打算兑现我的承诺，用 Python 模拟演示上面的例子。**

**贝叶斯统计是[量化策略](https://quantra.quantinsti.com/course/quantitative-trading-strategies-models)的重要组成部分，量化策略是算法交易员手册的一部分。由 [QuantInsti](https://www.quantinsti.com/) 教授的[算法交易(EPAT)](https://www.quantinsti.com/epat/)高管课程涵盖统计&计量经济学、金融计算&技术和算法&量化交易等培训模块，让你具备应用各种交易工具和平台成为成功交易者所需的技能。**

***免责声明:股票市场的所有投资和交易都有风险。在金融市场进行交易的任何决定，包括股票或期权或其他金融工具的交易，都是个人决定，只能在彻底研究后做出，包括个人风险和财务评估以及在您认为必要的范围内寻求专业帮助。本文提到的交易策略或相关信息仅供参考。***