# 交易中的主成分分析

> 原文：<https://blog.quantinsti.com/principal-component-analysis-trading/>

以[重香重香](https://www.linkedin.com/in/rekhit/)

随着交易变得自动化，我们已经看到交易者试图使用尽可能多的数据进行分析。但我们都知道，增加更多的变量会导致更多的复杂情况，这反过来可能会使我们更难得出可靠的结论。想想看，我们在纽约证券交易所有 3000 多家公司。一个简单的寻找它们之间配对的练习将会是计算密集型的。如果我们可以使用很多变量，但仍然以某种方式使它更简单，这不是很好吗？

别担心，我的朋友。我们有了答案，或者说，主成分分析就是答案。

如果我们必须描述主成分分析的有用性，我们会说它帮助我们减少了我们必须分析的数据量。如果你还是很迷茫，也不用担心。我们将在这个博客中讨论以下主题。

*   [什么是主成分分析？](#What)
*   [特征向量和协方差矩阵](#Eigen)
*   [什么时候用主成分分析？](#When)
*   [交易中的主成分分析](#Principal)

## 什么是主成分分析？

主成分分析是降维方法之一，本质上是创造一个新的变量，这个变量包含了原变量中的大部分信息。例如，如果我们有 10 家公司 5 年的收盘价数据，即大约 1265 个数据点* 10。我们将寻求以保存信息的方式减少这一数字。

当然，在现实世界中，会有一些信息损失，因此，我们使用主成分分析，以确保它保持在最低限度。

这听起来很有趣，但是我们到底该怎么做呢？

答案是特征值。这不是全部答案，但在某种程度上是。在我们进入它的数学之前，让我们刷新我们关于矩阵的概念(不，不是电影！).如果您想跳过复习课程，请单击此链接继续。

## 特征向量和协方差矩阵

特征向量和特征值的主要应用之一是在图像变换中。还记得我们如何在任何照片编辑应用程序中倾斜图像吗？特征值和特征向量在这方面有帮助。

基本上，当我们把一个向量乘以一个矩阵时，向量就被转换了。我们所说的变换是指向量的方向和大小可能会改变。然而，有些矢量的方向是不变的。然而，幅度可能会改变。从形式上来说，对于变换矩阵 A 和向量 v，情况是这样的:

**Av = λv**

当与一个矩阵相乘时，这种向量的整个集合不改变方向，称为特征向量。相应的幅度变化称为特征值。这里用λ表示。

记得我们说过主成分分析的最终目的是减少变量的数量。特征向量和特征值在这方面有帮助。要遵循的一件事是，特征向量用于正方形矩阵，即具有相等数量的行和列的矩阵。但是也可以对矩形矩阵进行计算。

假设我们有一个矩阵 A，它由以下元素组成:

| Two | eight |
| six | Ten |

现在，我们必须以这样的方式找到特征向量和特征值:

### Av = λv

在哪里，

v 是由特征向量组成的矩阵，并且

λ是特征值

虽然这听起来令人望而生畏，但有一个简单的方法来寻找特征向量和特征值。

让我们将该等式修改为以下等式，

Av = λIv(我们知道 AI = A)

如果我们把 RHS 的值带到 lhs，那么，

Av - λIv = 0

现在，我们将假设特征向量矩阵非零。这样，我们就可以通过求行列式来求λ。

因此，| A - λI | = 0

(2-λ)10-λ(8 * 6)= 0

20 到 2λ+λ^ 2 到 48 = 0

-28 -12λ加λ^2 = 0

λ^ 2-12-28 = 0

(λ - 14)(λ +2) = 0

λ= 14-2

因此，我们可以说特征值是 14，-2。

取λ值为-2。我们现在将找到特征向量矩阵。

回想一下，Av = λv

假设特征向量矩阵如下:

![](img/aa8412f3cb49b267b50d234dd86461a1.png)

(2x + 6y) = -2x

(8x + 10y) = -2y

(4x + 6y) = 0

(8x + 12y) = 0

因为它们相似，求解它们得到，2x + 3y = 0，x = (-3/2)y

X = -3，y = 2

因此，特征向量矩阵为

![](img/62318630bb68e542e42cc5fb3c2e49dd.png)

现在整个方程可以用下面的方式来写，

![](img/291c5e6fb7a68b338dbe3f67ffdcb997.png)

类似地，对于λ = 14，特征向量是 x =1，y = 2

太棒了。我们已经了解了特征向量和特征值是如何形成的。等等，让我们问自己一个简单的问题，在等式的两边，L.H.S 看起来简单还是 R.H.S？

既然知道了如何求特征值和特征向量，那就来说说它们的性质吧。

在我们之前的例子中，我们有一个 2 x 2 矩阵。这可以被认为是二维的。关于特征向量和特征值的一个伟大的事情是，它们被用于“正交变换”，这是一个有趣的词，表示变量随着方向的改变而在另一个轴上移动。让我们举一个直观的例子。

![](img/0e7b4fa5c8f8aced9551a238adf53931.png)

假设我们有以下映射在 x 和 y 轴上的值。现在你可以通过给出一个点的(x，y)坐标来定位它们，但是我们意识到有另外一种有效的方法来有意义地显示它们。

如果我们以这样一种方式画一条线，我们可以用这条新线上的一个点和这些点之间的距离来确定它们的位置。让我们现在试试。

![](img/46408f2cffb932bbcfc06026f6fcd09c.png)

假设绿线代表从每个点到新线的距离。此外，从投影线上的第一个点到新线上的最后一个点的投影的距离在这里被称为扩散。在上图中，用红线表示。分布的重要性在于它给我们提供了关于数据集变化程度的信息。值越大，我们就越容易区分两个单独的数据点。

我们应该注意到，如果我们有二维变量，那么我们将得到两组特征值和特征向量。另一条线实际上垂直于第一条线。

![](img/d8588df65e5a2b76f7016f8cc11d4f81.png)

现在，我们有了一个新的坐标轴，它更适合这些点，对吗？

让我们根据新的轴来绘制变量。

![](img/c8abd8a8b2d0c1593e49040abdba3fbf.png)

如果我们必须用图解法解释特征向量和特征值，我们可以说特征向量给出了它被拉伸或变换的方向，而特征值是它被拉伸的值。从这个意义上来说，第一行比第二行给了我们更多的信息。

![](img/5293c5fbf9ddc5ca67cacf4e1ace1db4.png)

但是为什么理解这一点很重要？当我们说特征值给了我们拉伸点的值时，我们应该进一步补充，具有相应较大数值的特征值比具有较小数值的特征值给了我们更多的信息。

哦，等等！本文谈主成分分析。嗯，特征值和特征向量实际上是数据的组成部分。

但是这个谜题还缺少一部分。正如我们看到的插图，数据点聚集在一起，因此点之间的距离并不重要。

但是，如果我们试图比较股票价格，一个价值不到 10 美元，另一个价值超过 500 美元，该怎么办呢？显然，价格本身的变化会导致不同的结果。因此，我们试图找到一种标准化数据的方法。既然我们试图找出差异，还有什么比使用协方差矩阵更好的方法呢？

### 协方差

协方差本质上是用来看两个对应变量运动的方向。让我们用一个真实世界的例子来快速解释协方差。

### 使用股票数据的协方差

假设我们投资组合中的“n”只股票(S1，S2，…Sn)的收盘价如下

![](img/45d5703e956c6713ab7d946338511006.png)

我们将把这些股票数据合并到一个矩阵中，并将其命名为“S”:

![](img/2a6bac774d03c4ce711cb24cc53ba5c1.png)

#### 股票平均价格

如你所见，每只股票都由过去“m”天的收盘价组成。使用这些数据，我们将首先计算每只股票的平均价格。

例如，股票“S1”的平均价格如下所示:

![](img/778f84f50b602eaf937aa77410c44734.png)

接下来，我们将“n”只股票的所有平均值保存在一个名为“M”的矩阵中，如下所示:

![](img/fe38127575da33845b0bac57dd9f4f4c.png)

我们的最终目标是理解一只股票的行为与另一只股票的行为之间的关系。要比较两只价格区间完全不同的股票，首先需要建立一个共同的基础。因此，为了使股票走势的比较更加均衡，我们从股票价格中减去股票价格的平均值。

这将创建一个新的去均值股票价格，这将有助于比较一只股票的运动如何从其均值依赖于另一只股票的运动从其均值。让我们了解如何创建一个去意义的系列。

#### 降低价格

首先，我们从相应股票的收盘价中减去平均股价。这将为我们提供具有去均值得分的矩阵，或者一个数据点离其均值有多远的度量。

![](img/5a318cd7791172fd435efa1a8a781e11.png)

#### 协方差矩阵

一旦我们有了去均值价格序列，我们通过将去均值价格序列的转置与其自身相乘并除以“m”(数据点的数量)来建立不同股票的协方差，这给出了协方差矩阵:

![](img/49b16af1d174c0c1198f0dbfa587fbe6.png) ![](img/7c8bb9f2db6715be338105fe3db6f487.png)

在生成的协方差矩阵中，对角线元素表示股票的方差。

此外，协方差矩阵沿对角线对称，这意味着:

σ21 = σ12

因此，通过这种方式，我们可以找到数据集的方差和协方差。如果你对投资组合差异感兴趣，那就去这个[博客](/calculating-covariance-matrix-portfolio-variance/)吧。上面的协方差的定义也是从那里得到的。

好吧。所以我们知道，主成分分析作为一种压缩工具，寻求降低数据的维度，以使计算更容易。我们也看到了特征向量和特征值如何使原始矩阵更简单。此外，我们知道协方差极大地简化了寻找特征值和特征向量的整个过程。

现在回想一下，最初，我们讨论了主成分分析如何通过将两个变量转换为一个变量，通过创建一个新的特征来降低维数。你是否在脑海中形成了一幅我们如何在交易中使用它的画面？

假设我们找到了协方差矩阵的特征值和特征向量，我们会说最大的特征值拥有关于协方差矩阵的最多信息。因此，我们可以保留一半的特征值及其对应的特征向量，并且仍然能够包含协方差矩阵中存在的大部分信息。

如果我们选择了 4 个特征值及其对应的特征向量，我们将说我们选择了 4 个主分量。

这就是全部了。以之前的例子为例，如果我们选择了特征值 14，我们会丢失一些信息，但它极大地简化了计算，从这个意义上说，我们降低了变量的维数。

咻！我们实际上已经理解了主成分分析是如何工作的。如果我们必须在这里添加另一个注释，并尝试加强 PCA 中特征向量的使用，我们可以看到协方差矩阵的特征值之和大约等于原始矩阵中总方差之和。

但心里还是有一个疑问。

## 什么时候用主成分分析？

假设您正在处理一个大型数据集，并且觉得可以删除某些变量而不会造成大量信息损失，那么我们应该使用主成分分析。事实上，这对我们的配对交易策略有很大的帮助。让我们试试，好吗？

## 交易中的主成分分析

幸运的是，我们不必用 Python 编写主成分分析的整个逻辑。我们将简单地导入 **sklearn** 库，并使用已经定义的 PCA 函数。

由于我们正在寻求全球实施，我们将使用在纽约证券交易所上市的股票。

由于我们将处理许多公司的数据，我们创建了一个 csv 文件，其中包含在纽约证券交易所上市的 90 家公司的股票代码。我们暂时将导入其中 50 种的“调整后收盘价”。代码如下。

```py
import yfinance as yf
import pandas as pd
stock_df = pd.read_csv('stock_list.csv')
stock_df.head()
data = pd.DataFrame()
for ticker in stock_df.Symbols[:50]:
data[ticker] = yf.download(ticker,'2018-1-1','2019-12-31')['Adj Close']
data.head()
data.to_csv('pca.csv')
```

由于我们将处理每日回报，我们编写如下代码。

```py
data_daily_returns = df.pct_change()
data_daily_returns.dropna(inplace=True)
```

如果我们必须检查数组的行数和列数，我们使用下面的代码。

```py
data_daily_returns.shape
```

(203, 50)

这里，我们知道有 50 列对应于我们选择的公司数量，203 列是我们拥有的每个公司的数据点。接下来，我们将使用主成分分析代码。由于我们试图减少变量，让我们保持主成分的数量为 30。

```py
from sklearn.decomposition import PCA
N_PRINCIPAL_COMPONENTS = 30
pca = PCA(n_components=N_PRINCIPAL_COMPONENTS)
pca.fit(data_daily_returns)
```

您可以使用“shape”命令检查数组中的行数和列数。

pre_process = pca.components_。t 预处理.形状

(50, 30)

现在，我们将尝试使用这个结果，并检查我们是否可以根据相似性对数据进行聚类。

```py
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn import preprocessing
from statsmodels.tsa.stattools import coint
pre_process = preprocessing.StandardScaler().fit_transform(X)
print(pre_process.shape)
kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=30, n_init=10, random_state=7)
kmeans.fit(pre_process)
labels = kmeans.labels_
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
print("\nClusters discovered: %d" % n_clusters_)
clustered = kmeans.labels_
```

输出将如下所示，

```py
KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=30,
n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',
 random_state=7, tol=0.0001, verbose=0)
```

发现的集群:3

为了将其可视化，我们将使用 t-SNE 工具，该工具用于将高维数据可视化为二维数据。

确切的代码如下:

```py
clustered_series = pd.Series(index=data_daily_returns.columns, data=clustered.flatten())
clustered_series_all = pd.Series(index=data_daily_returns.columns, data=clustered.flatten())
clustered_series = clustered_series[clustered_series != -1]
pre_process_tsne = TSNE(learning_rate=1000, perplexity=25, random_state=1337).fit_transform(pre_process)
import matplotlib.pyplot as plt
plt.figure(1, facecolor='white')
plt.clf()
plt.axis('off')
plt.scatter(
pre_process_tsne[(labels!=-1), 0],
pre_process_tsne[(labels!=-1), 1],
s=100,
alpha=1.5,
c=labels[labels!=-1]
)
plt.scatter(
pre_process_tsne[(clustered_series_all==-1).values, 0],
pre_process_tsne[(clustered_series_all==-1).values, 1],
s=50,
alpha=0.05
)
plt.title('T-SNE of all Stocks with KMeans Clusters');
```

因此，输出将是，

![](img/e922713065d197a405eda8abd209cb92.png)

现在让我们来回答一些常见的问题

## 常见问题

#### 我是否需要通过去掉平均值并应用协整来规范化我的代码 it 中使用的价格序列？PCA 不是内部做吗？

是的，在应用 PCA 之前，您必须对输入进行标准化。这不是由 PCA 函数完成的。

#### 我需要手动生成抽象因子吗？PCA 不就是提取抽象因素的方法吗？

PCA 可以用来生成抽象因子。

#### 应该如何用抽象因子来实现？

特征向量是你的“主成分”。它们用于获得套利策略中使用的残差。具有最高特征值的特征向量对应于最重要的因子。

#### 在 PCA 投资组合交易中，什么是 alpha？你将如何推导它？

投资组合相对于基准指数回报的超额回报是投资组合的 alpha。

## 结论

自本文开始以来，我们已经走过了漫长的道路。我们不仅用协方差更新了我们对基本统计学的理解，而且用特征值和特征向量的形式更新了矩阵变换。我们也知道如何通过建立配对交易策略来使用它们进行主成分分析。

*免责声明:本文中提供的所有数据和信息仅供参考。QuantInsti 对本文中任何信息的准确性、完整性、现时性、适用性或有效性不做任何陈述，也不对这些信息中的任何错误、遗漏或延迟或因其显示或使用而导致的任何损失、伤害或损害承担任何责任。所有信息均按原样提供。*

点击下载按钮获取我们在博客中使用的代码。