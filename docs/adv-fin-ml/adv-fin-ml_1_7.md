# 第九章：交叉验证下的超参数调优

## 9.1 动机

超参数调优是拟合机器学习算法的重要步骤。如果这一步没有做好，算法可能会过拟合，实际表现会令人失望。机器学习文献特别关注对任何调优超参数进行交叉验证。正如我们在第七章中看到的，金融领域的交叉验证（CV）是一个特别困难的问题，其他领域的解决方案可能会失败。在本章中，我们将讨论如何使用清除的 k 折 CV 方法进行超参数调优。参考文献部分列出了提出可能在特定问题中有用的替代方法的研究。

## 9.2 网格搜索交叉验证

网格搜索交叉验证根据用户定义的得分函数对最大化 CV 性能的参数组合进行彻底搜索。当我们对数据的底层结构了解不多时，这是一种合理的初步方法。Scikit-learn 在`GridSearchCV`函数中实现了这一逻辑，该函数接受 CV 生成器作为参数。由于第七章中解释的原因，我们需要传递`PurgedKFold`类（代码片段 7.3），以防止`GridSearchCV`对泄漏信息过拟合 ML 估计器。

> **代码片段 9.1 使用清除的 K 折交叉验证的网格搜索**
> 
> ![](img/Image00387.jpg)

代码片段 9.1 列出了函数`clfHyperFit`，该函数实现了清除的`GridSearchCV`。参数`fit_params`可用于传递`sample_weight`，而`param_grid`包含将组合成网格的值。此外，该函数允许对调优的估计器进行集成。对估计器进行集成通常是个好主意，原因在第六章中已解释，上述函数包含了为此目的的逻辑。

我建议你在元标签应用的上下文中使用`scoring=‘f1’`，原因如下。假设样本中有大量负面（即，标签为‘0’）案例。一个将所有案例预测为负面的分类器将获得高`‘accuracy’`或`‘neg_log_loss’`，尽管它并未从特征中学习如何区分案例。实际上，这种模型的召回率为零，精确度未定义（见第三章第 3.7 节）。`‘f1’`分数通过从精确度和召回率的角度评分分类器来纠正这种性能膨胀（见第十四章第 14.8 节）。

对于其他（非元标签）应用，使用`‘accuracy’`或`‘neg_log_loss’`是可以的，因为我们对所有案例的预测都同样感兴趣。请注意，对案例的重新标记对`‘accuracy’`或`‘neg_log_loss’`没有影响，但会对`‘f1’`产生影响。

此示例很好地引入了 sklearn 的`Pipelines`的一个限制：它们的拟合方法不期望`sample_weight`参数，而是期望一个带关键字的`fit_params`参数。这是一个已在 GitHub 上报告的错误；不过，修复可能需要一些时间，因为这涉及到重写和测试大量功能。在那之前，可以自由使用代码片段 9.2 中的解决方法。它创建了一个新类，称为`MyPipeline`，该类继承了 sklearn 的`Pipeline`中的所有方法。它用一个新的方法覆盖继承的`fit`方法，该方法处理参数`sample_weight`，然后重定向到父类。

> **代码片段 9.2 增强型管道类**
> 
> ![](img/Image00389.jpg)

如果你不熟悉扩展类的这种技术，建议阅读这个入门的 Stackoverflow 文章：[`stackoverflow.com/questions/ 576169/understanding-python-super-with-init-methods`](http://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods)。

## 9.3 随机搜索交叉验证

对于参数数量较多的机器学习算法，网格搜索交叉验证 (CV) 变得计算上不可行。在这种情况下，一个具有良好统计特性的替代方案是从一个分布中抽样每个参数（Begstra 等人 [2011, 2012]）。这有两个好处：首先，我们可以控制搜索的组合数量，而不考虑问题的维度（相当于计算预算）。其次，性能上相对无关的参数不会显著增加我们的搜索时间，这与网格搜索 CV 的情况相反。

与其编写一个新的函数来处理 `RandomizedSearchCV`，不如扩展代码片段 9.1，加入一个选项。一个可能的实现是代码片段 9.3。

> **代码片段 9.3 使用清除 K 折交叉验证的随机搜索**
> 
> ![](img/Image00391.jpg)

**9.3.1 对数均匀分布**

一些机器学习算法通常仅接受非负超参数。这就是一些非常流行的参数的情况，例如 SVC 分类器中的 `C` 和 RBF 核中的 `gamma`。^(1) 我们可以从一个界定在 0 和某个大值（例如 100）的均匀分布中抽取随机数。这意味着 99% 的值预计会大于 1。这并不一定是探索非线性响应参数的可行区域的最有效方法。例如，SVC 对于将 `C` 从 0.01 增加到 1 的反应与将 `C` 从 1 增加到 100 的反应是一样的。^(2) 因此，从 *U* [0, 100]（均匀）分布中抽样 `C` 将是低效的。在这种情况下，似乎从对数分布均匀抽取值更为有效。我称之为“对数均匀分布”，由于在文献中找不到这个定义，我必须对其进行恰当的定义。

随机变量 *x* 在 *a* > 0 和 *b* > *a* 之间遵循对数均匀分布，当且仅当 log [ *x* ] ∼ *U* [log [ *a* ], log [ *b* ]]。该分布的累积分布函数 (CDF) 为：

![](img/Image00394.jpg)

从中，我们得出一个 PDF：

![](img/Image00569.jpg)

![](img/Image00401.jpg)

**图 9.1** 测试 `logUniform_gen` 类的结果

请注意，CDF 对对数的底数是不变的，因为！[](Image00403.jpg)，对任何底数 *c* 都是如此，因此随机变量不是 *c* 的函数。Snippet 9.4 在 `scipy.stats` 中实现（并测试）了一个随机变量，其中 [ *a* , *b* ] = [1 *E* − 3, 1 *E* 3]，因此 log [ *x* ] ∼ *U* [log [1 *E* − 3], log [1 *E* 3]]。  图 9.1  显示了样本在对数尺度上的均匀性。

> **SNIPPET 9.4 THE** `**LOGUNIFORM_GEN**` **CLASS**
> 
> ![](img/Image00406.jpg)
