# 高效灵活的概率建模方法基于 Python

> 原文：[`mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&mid=2653285768&idx=1&sn=2a8919a04d3ad7eea49305e36104f97b&chksm=802e2f9db759a68b9bdd9588488d2ff79c4b11ea9e9defc1a22b8d90d29fba3deb64c33ba7c7&scene=27#wechat_redirect`](http://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&mid=2653285768&idx=1&sn=2a8919a04d3ad7eea49305e36104f97b&chksm=802e2f9db759a68b9bdd9588488d2ff79c4b11ea9e9defc1a22b8d90d29fba3deb64c33ba7c7&scene=27#wechat_redirect)

![](img/cb3bd660442e6bc134fbecf2477c43d1.png)

**编辑部**

微信公众号

**关键字**全网搜索最新排名

**『量化投资』：排名第一**

**『量       化』：排名第一**

**『机器学习』：排名第四**

我们会再接再厉

成为全网**优质的**金融、技术类公众号

**前言**

在今天给大家介绍一个研究工具：**pomegranate。**它比其他软件包更加灵活，更快，直观易用，并且可以在多线程中并行完成。

![](img/0c8914c4f000bb6e1dba4a67150b39a5.png)

![](img/df5cf1ce21b60f09b1a60376a4fe4403.png)

**The API**

**主要模型介绍**

*   一般混合模型

*   隐马尔可夫模型

*   贝叶斯网络

*   贝叶斯分类器

**所有模型使用做多的方法**

model.log_probability(X) / model.probability(X)
model.sample()
model.fit(X, weights, inertia)
model.summarize(X, weights)
model.from_summaries(inertia)
model.predict(X)
model.predict_proba(X)
model.predict_log_proba(X)
model.from_samples(X, weights)

**支持很多分布函数**

**单变量分布** 1\. UniformDistribution
    2\. BernoulliDistribution
    3\. NormalDistribution
    4\. LogNormalDistribution
    5\. ExponentialDistribution
    6\. BetaDistribution
    7\. GammaDistribution
    8\. DiscreteDistribution
    9\. PoissonDistribution

**内核密度**

    1\. GaussianKernelDensity
    2\. UniformKernelDensity
    3\. TriangleKernelDensity

**多变量分布**

    1\. IndependentComponentsDistribution
    2\. MultivariateGaussianDistribution
    3\. DirichletDistribution
    4\. ConditionalProbabilityTable
    5\. JointProbabilityTable

**模型可以从已知值中创建**

![](img/5b1b10114c06b0226d1adc915a7d67ab.png)

**模型也可以从数据直接学习**

![](img/264376886a8b23442d572f22d39eb64b.png)

**pomegranate 比 numpy 快**

![](img/a5dcfd32f24af0b7feb0c540485dca05.png)

![](img/ce233eaf1438a43c1275d692250b3db2.png)

只需要一次数据集（适用于所有模型）。以下是正态分布统计示例：

![](img/42f50440ef0924d83c42db7e9fd42fe3.png)

**支持核心学习**

由于使用了足够多的统计数据，因此可以支持外核/在线学习。

![](img/65d42ccb42ad0374cd8e946542be792a.png)

**pomegranate 比 scipy 快**

![](img/de10407fe6ff03dd1dbb43cebeab5864.png)

**The API**

**主要模型介绍**

*   **一般混合模型**

*   隐马尔可夫模型

*   贝叶斯网络

*   贝叶斯分类器

**通用混合模型（GMM）可以对多组****分布进行建模**

![](img/200dc49251c236bf49031e32bbe6ce0a.png)

GMM 使用期望最大化（EM）来拟合

    1、使用 kmeans ++或 kmeans ||初始化集群

    2、对于等于后 P（M | D）（E 步）的所有点分配权重

    3、使用加权点更新分布（M 步）

    4、重复 2 和 3，直到收敛

![](img/cba16599ed95dca6e86d989724908860.png)

model = GeneralMixtureModel.from_samples(NormalDistribution, 2, X) 

**GMM 不限于高斯分布**

![](img/52a7e39847edd0afb14db4f519002499.png)

**单个指数分布不能很好的数据进行建模**

![](img/9121493ec2883d342c517a57b90d04cb.png)

model = ExponentialDistribution.from_samples(X)

**两个指数混合使数据更好的模拟**

![](img/727f45a20e4fb943e7ac5ddc553dfeee.png)

model = GeneralMixtureModel.from_samples(ExponentialDistribution, 2, X)

**Heterogeneous mixtures are natively supported**

![](img/c730a7244b9cbe544b0a5a2feb5dfe38.png)

model = GeneralMixtureModel.from_samples([ExponentialDistribution, UniformDistribution], 2, X)

**一般混合模型比 sklearn 快**

![](img/32602548600860c5d0df91e460af72c2.png)

**The API**

**主要模型介绍**

*   一般混合模型

*   **隐马尔可夫模型**

*   贝叶斯网络

*   贝叶斯分类器

**CG enrichment detection HMM**  

GACTACGACTCGCGCTCGCGCGACGCGCTCGACATCATCGACACGACACTC

![](img/3e845fa457b3a05e0a382f478f10bf37.png)

![](img/8c29b2eba70a36acac11eef68fc823ce.png)

![](img/eb1bf35eee7202faa4efaabee0456f28.png)

![](img/1459452f1447b9fc9085503f6805051c.png)

**GMM-HMM**

![](img/29dc07b42190f38d51c58faed1af0c48.png)

**HMM 比 hmmlearn 快**

![](img/0285bb49d6d721ef999f96556ef97735.png)

**The API**

**主要模型介绍**

*   一般混合模型

*   隐马尔可夫模型

*   **贝叶斯网络**

*   **贝叶斯分类器**

P(M|D)= P(D|M)P(M) / P(D)
Posterior = Likelihood * Prior / Normalization

**基于数据建立一个简单的分类器**

![](img/10db89d338e0925022e50a62e8740c0e.png)

**似然函数本身忽略了类不平衡**

![](img/c4fb39a6623da34b1a65ca4756a81bb7.png)

**先验概率可以模拟分类不平衡**

![](img/1bc3eae574734dcf16290783ed885d97.png)

**后验模型更真实地对原始数据进行建模**

![](img/875026130ce134fca66618a0e08814b3.png)

**后者的比例是一个很好的分类器**

![](img/ab6932634e63e958df4abc916ea224a3.png)

model = NaiveBayes.from_samples(NormalDistribution, X, y)
posteriors = model.predict_proba(idxs)

P(M|D)= ∏P(D|M) P(M) / P(D)
Posterior = Likelihood * Prior / Normalization

Naive Bayes does not need to be homogenous

![](img/aa4898d6596cb0d4ecba8bc736d8fe0f.png)

**不同的功能属于不同的分布**

![](img/104035e042751b62969cf62997eab019.png)

![](img/d8d556bdea36daeead2409db31db5216.png)

Gaussian Naive Bayes: 0.798
sklearn Gaussian Naive Bayes: 0.798
Heterogeneous Naive Bayes: 0.844

**与 sklearn 一样快**

![](img/4d8a7f5dcb706fa3171b4b6855c1eb0d.png)

P(M|D)= P(D|M) P(M) / P(D)
Posterior = Likelihood * Prior / Normalization

mc_a = MarkovChain.from_samples(X[y == 0])
mc_b = MarkovChain.from_samples(X[y == 1])
model_b = BayesClassifier([mc_a, mc_b], weights=numpy.array([1-y.mean(), y.mean()]))

 hmm_a = HiddenMarkovModel…
hmm_b = HiddenMarkovModel...
model_b = BayesClassifier([hmm_a, hmm_b], weights=numpy.array([1-y.mean(), y.mean()]))

 bn_a = BayesianNetwork.from_samples(X[y == 0])
bn_b = BayesianNetwork.from_samples(X[y == 1])
model_b = BayesClassifier([bn_a, bn_b], weights=numpy.array([1-y.mean(), y.mean()]))

**并行**

![](img/7c042a1f8a87ca9fa0c288d1e30a1d7c.png)

![](img/89c852faa3ab43ad487e8c58a3a35b6c.png)

**关注者**

**从****1 到 10000+**

**我们每天都在进步**

![](img/75adf94249ccd19cd678f27528ec406b.png)