# 留给人类的时间不多了？现在不学机器学习更待何时！

> 原文：[`mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&mid=2653286641&idx=1&sn=2eee8a45b62cbdee205033b54aa74dfd&chksm=802e32e4b759bbf2c111469db1ef9eb3901a3b12f3ba787e9e2548fc38546063f85ae0c3ab40&scene=27#wechat_redirect`](http://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&mid=2653286641&idx=1&sn=2eee8a45b62cbdee205033b54aa74dfd&chksm=802e32e4b759bbf2c111469db1ef9eb3901a3b12f3ba787e9e2548fc38546063f85ae0c3ab40&scene=27#wechat_redirect)

**立即参团**

原价 ¥899.00

目前已达最低价 ¥399.00

>>点击文末阅读原文参团<<

![](img/fc883889d23bc43c5614f07ec80541e1.png)

**机器学习**（升级版Ⅶ）

**课程目标：**本课程特点是**从数学层面推导最经典的机器学习算法，以及每种算法的示例和代码实现（Python）、如何做算法的参数调试、以实际应用案例分析各种算法的选择等。**

**主讲老师：**** 邹博 小象学院签约讲师 **

计算机博士，现科学院从事科研教学工作；主持国家级科研项目 2 个，副负责 1 个，国家专利 2 项，研究方向机器学习、数据挖掘、计算几何，应用于股票交易与预测、医药图像识别、智能畜牧等方向。擅长机器学习模型选择、核心算法分析和代码实现。

**开课时间：**2017 年 11 月 24 日

**学习方式：**

在线直播，共 24 次

每周 3 次（**周一、三、五晚上 20:00-22:00**）

直播后提供录制回放视频，在线反复观看，有效期 1 年

**升级版Ⅶ的内容特色：**

1.每个算法模块按照“**原理讲解→分析数据→自己动手实现→特征与调参**”的顺序，“原理加实践，顶天立地”。

2.**拒绝简单的“调包”**——增加 3 次“机器学习的角度看数学”和 3 次“Python 数据清洗和特征提取”，提升学习深度、降低学习坡度。

3.增加网络爬虫的原理和编写，从获取数据开始，重视将实践问题转换成实际模型的能力，分享工作中的实际案例或 Kaggle 案例：**广告销量分析、环境数据异常检测和分析、数字图像手写体识别、Titanic 乘客存活率预测、用户-电影推荐、真实新闻组数据主题分析、中文分词、股票数据特征分析**等。

4.强化**矩阵运算、概率论、数理统计**的知识运用，掌握机器学习根本。

5.阐述机器学习原理，提供配套源码和数据；确保“**懂推导，会实现**”。

6.删去过于晦涩的公式推导，代之以**直观解释**，增强**感性理解。**

7.对比不同的特征选择带来的预测效果差异。

8.重视**项目实践**(如工业实践、Kaggle 等)，重视落地。思考不同算法之间的区别和联系，提高在实际工作中**选择算法的能力。**

9.涉及和讲解的部分**Python 库**有：Numpy、Scipy、matplotlib、Pandas、scikit-learn、XGBoost、libSVM、LDA、Gensim、NLTK、HMMLearn，涉及的其他“小”库在课程的实践环节会逐一讲解。

**课程大纲**

**第一课：机器学习的数学基础 1 - 数学分析**

1.  机器学习的一般方法和横向比较

2.  数学是有用的：以 SVD 为例

3.  机器学习的角度看数学

4.  复习数学分析

5.  直观解释常数 e

6.  导数/梯度

7.  随机梯度下降

8.  Taylor 展式的落地应用

9.  gini 系数

10\. 凸函数

11\. Jensen 不等式

12\. 组合数与信息熵的关系

**第二课：机器学习的数学基础 2 - 概率论与贝叶斯先验**

1.  概率论基础

2.  古典概型

3.  贝叶斯公式

4.  先验分布/后验分布/共轭分布

5.  常见概率分布

6.  泊松分布和指数分布的物理意义

7.  协方差(矩阵)和相关系数

8.  独立和不相关

9.  大数定律和中心极限定理的实践意义

10.  深刻理解最大似然估计 MLE 和最大后验估计 MAP

11.  过拟合的数学原理与解决方案

**第三课：机器学习的数学基础 3 - 矩阵和线性代数** 

1.  线性代数在数学科学中的地位

2.  马尔科夫模型

3.  矩阵乘法的直观表达

4.  状态转移矩阵

5.  矩阵和向量组

6.  特征向量的思考和实践计算

7.  QR 分解

8.  对称阵、正交阵、正定阵

9.  数据白化及其应用

10.  向量对向量求导

11.  标量对向量求导

12.  标量对矩阵求导

**第四课：Python 基础 1 - Python 及其数学库** 

1.  解释器 Python2.7 与 IDE：Anaconda/Pycharm

2.  Python 基础：列表/元组/字典/类/文件

3.  Taylor 展式的代码实现

4.  numpy/scipy/matplotlib/panda 的介绍和典型使用

5.  多元高斯分布

6.  泊松分布、幂律分布

7.  典型图像处理

8.  蝴蝶效应

9.  分形与可视化

**第五课：Python 基础 2 - 机器学习库** 

1.  scikit-learn 的介绍和典型使用

2.  损失函数的绘制

3.  多种数学曲线

4.  多项式拟合

5.  快速傅里叶变换 FFT

6.  奇异值分解 SVD

7.  Soble/Prewitt/Laplacian 算子与卷积网络

8.  卷积与(指数)移动平均线

9.  股票数据分析

**第六课：Python 基础 3 - 数据清洗和特征选择** 

1.  实际生产问题中算法和特征的关系

2.  股票数据的特征提取和应用

3.  一致性检验

4.  缺失数据的处理

5.  环境数据异常检测和分析

6.  模糊数据查询和数据校正方法、算法、应用

7.  朴素贝叶斯用于鸢尾花数据

8.  GaussianNB/MultinomialNB/BernoulliNB

9.  朴素贝叶斯用于 18000+篇/Sogou 新闻文本的分类

**第七课： 回归** 

1.  线性回归

2.  Logistic/Softmax 回归

3.  广义线性回归

4.  L1/L2 正则化

5.  Ridge 与 LASSO

6.  Elastic Net

7.  梯度下降算法：BGD 与 SGD

8.  特征选择与过拟合

**第八课：Logistic 回归**

1.  Sigmoid 函数的直观解释

2.  Softmax 回归的概念源头

3.  Logistic/Softmax 回归

4.  最大熵模型

5.  K-L 散度

6.  损失函数

7.  Softmax 回归的实现与调参

**第九课：回归实践** 

1.  机器学习 sklearn 库介绍

2.  线性回归代码实现和调参

3.  Softmax 回归代码实现和调参

4.  Ridge 回归/LASSO/Elastic Net

5.  Logistic/Softmax 回归

6.  广告投入与销售额回归分析

7.  鸢尾花数据集的分类

8.  交叉验证

9.  数据可视化

**第十课：决策树和随机森林**

1.  熵、联合熵、条件熵、KL 散度、互信息

2.  最大似然估计与最大熵模型

3.  ID3、C4.5、CART 详解

4.  决策树的正则化

5.  预剪枝和后剪枝

6.  Bagging

7.  随机森林

8.  不平衡数据集的处理

9.  利用随机森林做特征选择

10\. 使用随机森林计算样本相似度

11\. 数据异常值检测

**第十一课：随机森林实践** 

1.  随机森林与特征选择

2.  决策树应用于回归

3.  多标记的决策树回归

4.  决策树和随机森林的可视化

5.  葡萄酒数据集的决策树/随机森林分类

6.  波士顿房价预测

**第十二课：提升** 

1.  提升为什么有效

2.  梯度提升决策树 GBDT

3.  XGBoost 算法详解

4.  Adaboost 算法

5.  加法模型与指数损失

**第十三课：提升实践**

1.  Adaboost 用于蘑菇数据分类

2\. Adaboost 与随机森林的比较

3.  XGBoost 库介绍

4.  Taylor 展式与学习算法

5.  KAGGLE 简介

6.  泰坦尼克乘客存活率估计

**第十四课：SVM** 

1.  线性可分支持向量机

2.  软间隔的改进

3.  损失函数的理解

4.  核函数的原理和选择

5.  SMO 算法

6.  支持向量回归 SVR

**第十五课：SVM 实践** 

1.  libSVM 代码库介绍

2.  原始数据和特征提取

3.  葡萄酒数据分类

4.  数字图像的手写体识别

5.  SVR 用于时间序列曲线预测

6.  SVM、Logistic 回归、随机森林三者的横向比较

**第十六课：聚类（上）**

1.  各种相似度度量及其相互关系

2.  Jaccard 相似度和准确率、召回率

3.  Pearson 相关系数与余弦相似度

4.  K-means 与 K-Medoids 及变种

5.  AP 算法(Sci07)/LPA 算法及其应用

**第十七课：聚类（下）** 

1.  密度聚类 DBSCAN/DensityPeak(Sci14)

2.  DensityPeak(Sci14)

3.  谱聚类 SC

4.  聚类评价 AMI/ARI/Silhouette

5.  LPA 算法及其应用

**第十八课：聚类实践** 

1.  K-Means++算法原理和实现

2.  向量量化 VQ 及图像近似

3.  并查集的实践应用

4.  密度聚类的代码实现

5.  谱聚类用于图片分割

**第十九课：EM 算法** 

1.  最大似然估计

2.  Jensen 不等式

3.  朴素理解 EM 算法

4.  精确推导 EM 算法

5.  EM 算法的深入理解

6.  混合高斯分布

7.  主题模型 pLSA

**第二十课：EM 算法实践** 

1.  多元高斯分布的 EM 实现

2.  分类结果的数据可视化

3.  EM 与聚类的比较

4.  Dirichlet 过程 EM

5.  三维及等高线等图件的绘制

6.  主题模型 pLSA 与 EM 算法

 **第二十一课：主题模型 LDA** 

1.  贝叶斯学派的模型认识

2.  Beta 分布与二项分布

3.  共轭先验分布

4.  Dirichlet 分布

5.  Laplace 平滑

6.  Gibbs 采样详解

**第二十二课：LDA 实践** 

1.  网络爬虫的原理和代码实现

2.  停止词和高频词

3.  动手自己实现 LDA

4.  LDA 开源包的使用和过程分析

5.  Metropolis-Hastings 算法

6.  MCMC

7.  LDA 与 word2vec 的比较

8.  TextRank 算法与实践

**第二十三课：隐马尔科夫模型 HMM** 

1.  概率计算问题

2.  前向/后向算法

3.  HMM 的参数学习

4.  Baum-Welch 算法详解

5.  Viterbi 算法详解

6.  隐马尔科夫模型的应用优劣比较

**第二十四课：HMM 实践** 

1.  动手自己实现 HMM 用于中文分词

2.  多个语言分词开源包的使用和过程分析

3.  文件数据格式 UFT-8、Unicode

4.  停止词和标点符号对分词的影响

5.  前向后向算法计算概率溢出的解决方案

6.  发现新词和分词效果分析

7.  高斯混合模型 HMM

8.  GMM-HMM 用于股票数据特征提取

（点击左下角**阅读原文**了解更多）

**参团！咨询！查看课程！**

**就点这里****！**

![](img/d829b3f5296a42703513d66582a3560b.png "箭头图标")