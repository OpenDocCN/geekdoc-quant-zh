
# 第十三章：金融中的深度学习：使用长短期记忆网络预测股票收益

Miquel N. Alonso, Gilberto Batres-Estrada 和 Aymeric Moulin

## 13.1 介绍

循环神经网络是捕捉序列顺序的模型，因此经常用于处理序列数据。RNN 是强大的模型，因为它们能够扩展到比常规神经网络更长的序列。它们遇到两个严重的问题：第一个与梯度消失有关，第二个与梯度爆炸有关 (Graves 2012; Hochreiter 和 Schmidhuber 1997; Sutskever 2013)。这两个问题都被 LSTM 解决了。近年来，LSTM 在语音识别和机器翻译等领域解决了许多问题，其中目标通常是将输入序列匹配到输出序列。LSTM 网络可用于解决分类和回归问题。在机器学习中，有两个重要的事情区分了这两个领域。第一个是输出的类型，在回归中，它取实数值，而在分类中，它取离散集合中的值。第二个是在训练期间使用的成本函数的类型。

本章内容安排如下。第 13.2 节介绍了与金融和深度学习相关的相关工作，第 13.3 节讨论了金融中的时间序列分析。

第 13.4 节介绍了一般的深度学习，第 13.5 节涵盖了 RNN，它的构建模块和训练方法。第 13.6 节描述了 LSTM 网络，第 13.7 节涵盖了我们试图用 LSTM 解决的金融问题，使用的数据和方法。在同一节中，我们呈现了结果。第 13.8 节总结。

## 13.2 相关工作

多年来，金融和神经网络之间的研究很少，特别是使用 RNN。 最近，有一些非常有趣的论文发表在这个主题上，例如 Lee 和 Yoo (2017) 研究了投资组合的构建，并专注于交易的 10 只股票。 他们构建的投资组合在各种阈值水平上展现出一致的风险-收益特征。 他们的 LSTM 具有 100 个隐藏单元的隐藏层。 Fischer 和 Krauss (n.d.) 进行了一项详尽的研究，比较了许多机器学习算法，并表明 LSTMs 在研究中的其他模型中表现更好。 他们审视了整个 S&P 500 列表。 根据他们的结果，他们在交易成本之前实现了每天 0.23%的回报。

## 13.3 金融中的时间序列分析

资产收益（例如股票的对数收益率）可以被视为随时间变化的随机变量的集合。 然后，这个随机变量 rt 是一个时间序列。 线性时间序列分析提供了研究这种系列动态结构的自然框架。 线性时间序列的理论包括平稳性、动态依赖性、自相关函数、建模和预测。

标准计量经济模型包括自回归（AR）模型、移动平均（MA）模型、混合自回归移动平均（ARMA）模型、季节性模型、单位根非平稳性、具有时间序列误差的回归模型，以及长程依赖的分数差分模型。

对于资产收益率 rt，简单模型试图捕捉 rt 与时间 t 之前可用信息之间的线性关系。 信息可能包含 rt 的历史值和随机向量 Y，描述了决定资产价格的经济环境。 因此，相关性在理解这些模型中起着重要作用。 特别是，感兴趣变量与其过去值之间的相关性成为线性时间序列分析的焦点。

这些相关性被称为串行相关性或自相关性。 它们是研究平稳时间序列的基本工具。 例如，Box–Jenkins ARIMA

利用过去的滞后变量本身和错误；GARCH 可以捕捉股票收益的波动率聚类。 另外，还有许多其他的衍生模型，如非线性 GARCH (NGARCH)，积分 GARCH

(IGARCH)，指数 GARCH (EGARCH) 在具有不同设置的情况下表现良好（Qian n.d.）。

## 13.3.1 多元时间序列分析

金融建模中最重要的领域之一是多元时间序列分析的建模。 我们有几个建模选择：



- 多元分布。

- Copulas：主要用于风险管理和监管目的。

- 因子模型：广泛用于预测、解释、降维、估计、风险和绩效归因。

- 多元时间序列模型。

向量自回归 (VAR) 模型是最广泛使用的多元时间序列统计方法之一。这些模型已被应用于各种应用程序，从描述经济和金融时间序列的行为到建模动态系统和估计脑功能连接。

VAR 模型在建模金融数据和检测各种类型异常方面表现良好，优于现有的最先进方法。基于线性自回归、移动平均模型的基本多元时间序列模型有：

向量自回归 VAR(p)



$$y^{t}=c+\sum_{i=1}^{p}\Phi_{i}y_{t-i}+e_{t}$$

向量移动平均 VMA(q)

$$y^{t}=c+\sum_{j=1}^{q}\Theta_{j}\varepsilon_{t-j}+\varepsilon_{t}$$

向量自回归移动平均 VARMA (p, q)

$$y^{t}=c+\sum_{i=1}^{p}\Phi_{i}y_{t-i}+\sum_{j=1}^{q}\Theta_{j}e_{t-j}+e_{t}$$

具有线性时间趋势的向量自回归移动平均 VARMAL(p, q)

$$y^{t}=c+\delta t+\sum_{i=1}^{p}\Phi_{i}y_{t-i}+\sum_{j=1}^{q}\Theta_{j}\varepsilon_{t-j}+\varepsilon_{t}$$

具有外生输入的向量自回归移动平均 VARMAX(p, q)

$$y^{t}=c+\beta x_{t}+\sum_{i=1}^{p}\Phi_{i}y_{t-i}+\sum_{j=1}^{q}\Theta_{j}e_{t-j}+e_{t}$$

结构向量自回归移动平均 SVARMA(p, q)

$$\Phi_{0}y_{t}=c+\beta x_{t}+\sum_{i=1}^{p}\Phi_{i}y_{t-i}+\sum_{j=1}^{q}\Theta_{j}\varepsilon_{t-j}+\Theta_{0}\varepsilon_{t}$$

方程中出现以下变量：

- yt 是时间 t 的响应时间序列变量向量。 yt 有 n 个元素。

- c 是偏移的恒定向量，有 n 个元素。

- i 为每个 i 都是 n×n 矩阵，其中 i 是自回归矩阵。有 p 个自回归矩阵，其中一些可能完全由零组成。

- t 是序列不相关的创新向量，长度为 n 的向量。 t 是具有协方差矩阵的多元正态随机向量。

- j 为每个 j 都是 n×n 矩阵，其中 j 是移动平均矩阵。有 q 个移动平均矩阵，其中一些可能完全由零组成。

-  是线性时间趋势系数的恒定向量，有 n 个元素。



- xt 是表示每个时间 t 的外生项的 r×1 向量，r 是外生系列的数量。外生项是响应时间序列 yt 之外的数据（或其他未建模的输入）。每个外生系列都出现在所有响应方程中。

-  是大小为 r 的回归系数的 n×r 恒定矩阵。因此，乘积 xt 是大小为 n 的向量。

LSTMs 提供了这些标准模型的非线性版本。该论文在实验 2 中使用具有外生变量的多元 LSTMs 进行股票选择预测。

## 机器学习模型在金融领域

在过去五年中，机器学习模型在金融应用领域获得了势头，这主要得益于在诸如图像识别和自然语言处理等领域取得了巨大成功。这些模型已被证明在建模非结构化数据方面非常有用。除此之外，机器学习模型能够灵活地对分类和回归问题中的非线性进行建模，并发现监督学习中的隐藏结构。像 XGBoost 和 AdaBoost 这样的弱学习器的组合尤其受欢迎。无监督学习是机器学习的一个分支，用于从由没有标签的响应组成的数据集中推断出结论——主成分分析就是一个例子。在金融中使用机器学习的挑战是重要的，因为与其他模型一样，它需要应对估计风险、潜在的非稳态、过度拟合以及在某些情况下的可解释性问题。

## 13.4 深度学习

深度学习是机器学习领域的一个热门研究领域，部分原因是它在人工智能领域取得了巨大成功，尤其是在计算机视觉、自然语言处理、机器翻译和语音识别等领域，另一部分原因是现在可以基于深度学习构建应用程序。基于深度学习的日常应用包括推荐系统、语音助手以及基于计算机视觉的搜索引擎技术，仅举几例。这一成功得益于现在可用的大量数据，今天通常被称为大数据，以及执行计算比以往任何时候都要快得多的可能性。今天，可以将计算从计算机的中央处理单元（CPU）移植到其图形处理单元（GPU）。另一种方法是将计算移植到本地网络或云中的计算机集群中。

“深度学习”一词用于描述训练深度神经网络的活动。有许多不同类型的架构和训练这些模型的不同方法。最常见的网络是前馈神经网络。

(FNN) 用于假定为独立同分布（i.i.d.）的数据。

与此同时，循环神经网络（RNNs）更适用于序列数据，如时间序列、语音数据、自然语言数据（Bengio et al. n.d.）和其他数据，其中独立同分布的假设不成立。在深度学习中，主要任务是学习或近似一些将输入 x 映射到输出 y 的函数 f。深度学习试图解决以下学习问题 yˆ = f(;x)，其中 x 是神经网络的输入，yˆ是其输出，而  是给出 f 的最佳拟合的一组参数。在回归中，yˆ将由实数组成，而在分类中，它将由分配给离散值集中的每个类的概率表示。

## 13.4.1 深度学习和时间序列

金融中的时间序列模型需要处理自相关性、波动率聚类、非高斯性以及可能的周期和制度。深度学习特别是 RNN 可以帮助建模这些风格化事实。因此，RNN 是一种更灵活的模型，因为它在其反馈连接中编码了时间上下文，这些连接能够捕捉基础系统的时间变化动态（Bianchi 等

n.d.；Schäfer 和 Zimmermann 2007）。 RNN 是一种特殊类别的神经网络，其特点是内部自连接，在原理上可以近似或模拟任何非线性动态系统，达到一定的准确度。

## 13.5 递归神经网络 13.5.1 介绍

RNN 适用于处理序列，其中输入可能是序列

（x1，x2，...，xT），其中每个数据点 xt 都是实值向量或标量值。

目标信号（y1，y2，...，yT）也可以是一个序列或标量值。RNN

架构与传统神经网络的架构不同。它具有递归连接或带有时间延迟的反馈。递归连接代表了 RNN 处理的序列历史的内部状态（Yu 和 Deng，2015 年）。反馈可以以许多方式实现。 RNN 架构的一些常见示例是从隐藏层中取出输出并将其与新到达的输入一起反馈到隐藏层。另一种形式的递归反馈是取出 t−1 时间步网络的输出信号，并将其作为新输入与 t 时间步的新输入一起反馈（Goodfellow 等人，2016 年）。

当在时间上展开 RNN（图 13.1）时，RNN 具有深层结构，其深度与网络的时间输入一样长。这种深度与常规深度神经网络不同，常规深度神经网络通过将隐藏单元层堆叠在一起来实现深度。在某种意义上，RNN 可以被认为在时间和特征空间中都具有深度，特征空间中的深度通过将隐藏单元层堆叠在一起来实现。甚至存在适用于视频处理、医学成像和其他多维序列数据的多维 RNN（Graves 2012）。

RNN 已成功地用于建模可变长度序列，如语言建模（Graves 2012；Sutskever 2013）、学习词嵌入（Mokolov 等，2013 年）和语音识别（Graves 2012）。

## 13.5.2 Elman 递归神经网络

Elman 递归神经网络（ERNN），也称为简单 RNN 或原始 RNN，被认为是 RNN 最基本的版本。大多数更复杂

![256_image_0.png](img/256_image_0.png)

$$(13.1)$$

RNN 架构，如 LSTM 和门控循环单元（GRUs），可以解释为 ERNN 的一种变体或扩展。 ERNN 已被应用于许多不同的上下文中。 在自然语言处理应用中，ERNN 表现出能够使用一组未注释的句子进行语法学习，以预测句子中的连续单词（Elman 1995; Ogata et al. 2007）。 Mori 和小笠原

(1993) 研究了 ERNN 在短期负载预测中的性能，并提出了一种学习方法，称为 '扩散学习'（一种基于动量的梯度下降），以避免在优化过程中出现局部最小值。 蔡等人（2007 年）使用混合算法训练了一个 ERNN，该算法结合了粒子群优化和进化计算，以克服基于梯度的方法的局部最小值问题。

RNN 中的层可以分为输入层、一个或多个隐藏层和一个输出层。 虽然输入和输出层以前馈连接为特征，但隐藏层包含循环连接。 在每个时间步 t，输入层处理串行输入 x 的组件 x[t] ∈ RNi。 时间序列 x 的长度为 T，可以包含实值、离散值、独热向量等。 在输入层中，每个组件 x[t] 与偏置向量 b[i] ∈ RNh 相加，其中 Nh 是隐藏层中的节点数，然后与输入权重矩阵 Wi h ∈ RNh×Nh 相乘。

网络的内部状态 h[t − ] ∈ RNh 从上一个时间间隔开始首先与偏置向量 b ∈ RNh 相加，然后乘以循环连接的权重矩阵 Wh h ∈ RNh×Nh。 然后，转换后的当前输入和过去的网络状态被组合并由隐藏层中的神经元处理，这些神经元应用非线性变换。 在时间步 t 的网络内部状态更新和网络输出的差分方程为：

$$\begin{array}{l}{{h(t)=f(W_{i}^{b}(x(t)+b_{i})+W_{i}^{b}(b(t-1)+b_{b}))}}\\ {{y(t)=g(W_{i}^{o}b(t)+b_{o})}}\end{array}$$

其中 f(⋅) 是神经元的激活函数，通常由 sigmoid 或双曲正切实现。 隐藏状态 h[t]，它在时间步 t 传递网络的记忆内容，通常用零向量初始化，并且依赖于过去的网络状态和输入。 输出 y[t] ∈ RNo 通过转换 g(⋅) 计算，通常在回归设置中是线性的，对于使用当前状态 h[t] 和偏置向量 bo ∈ RNo 应用于输出权重矩阵 Wh o ∈ RNT×No 的分类问题，则为非线性。 所有的权重矩阵和偏置都可以通过梯度下降进行训练，使用时间的反向传播（BPPT）过程。

除非另有说明，在以下内容中，为了简化表示，我们通过假设 x = [x;1]，h = [h;1]，y = [y;1] 并通过扩充 Whi，Whh，Wh o 来忽略偏置项附加一列。

## 13.5.3 激活函数

激活函数用于将神经网络的输入转换为特征空间中的输出，表达为权重和偏差的线性组合

## H = G(Wtx + B)

其中 T 表示权重矩阵的转置。在正向传播中，这些变换被传播并最终到达网络的最后一层，并成为整个网络的输出。这种转换是使神经网络学习非线性函数的关键。修正线性单元（ReLu）（图 13.2）是现代神经网络中使用的最常见的隐藏单元类型（Goodfellow 等人。

2016)。它定义为 g(z) = max{0,z}。

另一个激活函数是逻辑 Sigmoid，(x) = (1+exp.(−x))−1，它是一个可微的压缩函数（见图 13.2）。它的缺点之一是

![257_image_0.png](img/257_image_0.png)

当其参数变得太负或者变得太大时，学习变慢。如今，特别是在前馈神经网络中，不建议使用它。在 RNN 中，逻辑 Sigmoid 可用作隐藏单元和输出单元。tanh(x) 与 Sigmoid 非常相似，但其范围在区间 (−1,1) 内。它被用作所有类型的神经网络：FNN、RNN、LSTM 的激活函数。

## 13.5.4 训练循环神经网络

我们从对 RNN 训练过程的简短介绍开始这一节。

为了训练 RNN，我们需要在正向传播中计算成本函数。然后，我们反向传播网络产生的误差，并利用这些误差来优化模型的参数，使用梯度下降。

在 RNN 的背景下，用于计算梯度的算法称为时间反向传播（BPTT）。我们介绍损失和成本函数，然后展示模型参数是如何更新的，最后介绍 BPTT

算法。

## 13.5.5 损失函数

损失函数衡量了神经网络对训练数据中目标信号的预测与实际情况的差异。为了评估我们的模型是否在学习，我们在训练过程中计算成本（见下文），并在模型未见过的测试集上测试其泛化能力。根据我们希望应用 RNN 的预测任务，有几种损失函数可供选择。接下来我们将使用以下定义。令 y 为目标信号，f(x,) 为网络输出。对于二分类任务，目标属于集合 y = {0,1}。在这种情况下，损失函数为

(Bishop 2006)：



$$L(y,f(x,\theta))=-\sum_{i=1}^{n}y n\log f n+(1-y n)\log(1-f n).$$

其导出如下。来自二元分类问题的结果由伯努利分布描述 p(y ∣ x, ) = f(x, )

y(1−f(x, ))1−y。对伯努利分布取自然对数得到似然函数，在这种情况下等于成本函数，给出了所述结果。在这种情况下，输出由 f = (a) = (1+exp(−a))−1 给出，满足 0≤f(x,)≤1。对于多类分类，我们经常使用损失函数

$$L(y f(x,\theta))=\sum_{n=1}^{N}\sum_{k=1}^{K}-y_{kn}\,\log\,f_{k}(x_{n},\theta)$$

我们模型的输出由 softmax 函数给出

$$f_{k}(x,\theta)={\frac{\exp(a_{k}(x,\theta))}{\sum_{j}\exp(a_{j}(x,\theta))}}$$

满足条件 0≤fk ≤1 和 Pk fk = 1。在回归估计任务中，我们使用均方误差作为损失函数（Bishop 2006）



$$L(y,f(x,\theta))={\frac{1}{2}}\sum_{n=1}^{N}\| f_{n}\left(x_{n},\theta\right)-y_{n}\ |^{2}$$

$$0=-\log$$

其中 fn 是网络的输出，xn 是输入向量，n = 1, ... ,N，并且 yn 是相应的目标向量。在无监督学习中，主要任务之一是从一组密度中找到密度 p(x,)，以便最小化损失函数（Vapnik 2000）

L(p(x, )) = −log p(x*, )。

## 13.5.6 成本函数

通过最小化经验风险来实现学习。风险最小化原则可以定义如下（Vapnik 2000）。将损失函数 L(y,(x,)) 定义为学习机输出与目标信号 y 之间的差异。然后定义风险函数或成本函数为

$$J(\theta)=\int L(y,f(x,\theta))\mathrm{d}F(x,y)$$

其中 F(x,y) 是联合概率分布。机器学习算法然后必须找到最小化成本函数的最佳函数 f。实际上，我们必须依靠最小化经验风险，因为联合分布对于数据生成过程是未知的（Goodfellow 等人 2016）。经验成本函数由下式给出

$$\mathbb{E}_{x,y\sim{\hat{p}}(x,y)}[L(f(x,\theta),y)]={\frac{1}{m}}\sum_{i=1}^{m}L(f(x^{(i)},\theta),y^{(i)})$$

其中期望值 E 取自经验数据分布 ∧p(x,y)。

## 13.5.7 梯度下降

为了训练 RNN，我们利用梯度下降，一种用于找到成本函数或目标函数的最优点的算法，也称为目标函数。目标函数是衡量模型与真实目标的比较的一种方法。对于计算梯度下降，我们需要计算参数的成本函数的导数。对于训练 RNN，这可以通过后向传播通过时间（BPTT）来实现，稍后在本节中展示。如前所述，我们将忽略偏置项的推导。类似的恒等式可以从权重的恒等式中获得。

*梯度下降*的名字指的是权重的更新规则选择在权重空间中梯度最陡峭的方向进行下一步。要理解这意味着什么，让我们将损失函数 J(w)想象成由权重 w 张成的表面。当我们从 w 处向小步长 w +w 走时，损失函数的变化为 J 'wT ΔJ(w)。然后向量ΔJ(w)指向变化率最大的方向（Bishop 2006）。优化是找到满足以下条件的最优点：



$$\Delta J(w)=0.$$

若在第 n 次迭代中未找到最优点，我们可以沿着由 w 张成的表面继续向下走向−ΔJ(w)的方向，减少损失函数，直到最终找到最优点。在深度学习的背景下，很难找到唯一的全局最优点。原因在于深度学习中使用的深度神经网络是输入、权重和偏差的函数组合。这个函数组合跨越了许多隐藏单元层，使得成本函数成为权重和偏差的非线性函数，因此我们面临一个非凸优化问题。梯度下降由以下公式给出

$$w(t+1)=w(t)-\eta\Delta J(w(t))$$

其中 是学习率。在这种形式下，梯度下降一次处理所有数据以更新权重。这种学习形式称为*批量学习*，指的是在每次迭代中使用整个训练集来更新参数（Bishop 2006; Haykin 2009）。梯度下降不鼓励使用批量学习（Bishop 2006, p. 240），因为有更好的批量优化方法，如共轭梯度或拟牛顿方法（Bishop 2006）。更适合使用梯度下降的是它的*在线学习*版本（Bishop 2006; Haykin 2009）。这意味着在每次迭代后，使用部分数据或单个数据点更新参数。成本函数的形式为

$$J(w)=\sum_{n=1}^{N}J_{n}(w)$$

其中求和对每个数据点进行。这导致了在线或随机梯度下降算法

$$w(t+1)=w(t)-\eta\Delta J_{n}(w(t)).$$

它的名字，即随机梯度下降，源自于参数的更新是逐个训练样本进行或者随机选择点进行（Bishop 2006）。

13.5.7.1 时域反向传播算法 用于计算梯度的梯度下降算法，在 RNN 的情况下，称为 BPTT。它类似于用于训练常规 FNN 的常规反向传播算法。通过在时间上展开 RNN，我们可以通过向后传播错误来计算梯度。让我们将成本函数定义为平方误差的和（Yu and Deng 2015）：

$$J={\frac{1}{2}}\sum_{t=1}^{T}\| \tau_{t}-y_{t}\ |^{2}={\frac{1}{2}}\sum_{t=1}^{T}\sum_{j=1}^{L}\left(\tau_{t}(j)-y_{t}(j)\right)^{2}$$

其中 t 表示目标信号，y_t 表示 RNN 的输出。变量 t 的总和在时间步 t = 1, t, ... , T 上运行，变量 j 的总和在单元 j 上运行。为了进一步简化表示，让我们重新定义 RNN 的方程为：



$$\begin{array}{l}{{h_{t}=f(W^{T}h_{t-1}+U^{T}x_{t}+b)}}\\ {{y_{t}=g(V^{T}h_{t}).}}\end{array}$$

h_t = f(W^T h_{t-1} + *U^T x_t* + b) (13.3)

y_t = g(*V_T h_t*). (13.4)

通过方程 (13.3) 和 (13.4) 以及使用局部势或激活势 u_t = W^T h_{t-1} + U^T x_t 和 v_t = V^T h_t，我们可以定义误差 (Yu 和 Deng 2015)

$$(13.3)$$

$$(13.4)$$

$$\delta_{t}^{y}(j)=-\frac{\partial J(\theta)}{\partial v_{t}(j)}$$  $$\delta_{t}^{b}(j)=-\frac{\partial J(\theta)}{\partial u_{t}(j)}$$

$$(13.5)$$  $$(13.6)$$

作为成本函数相对于单元势的梯度。BPTT

逐步迭代地计算时间步 t = T 到 t = 1 上的梯度。

对于最终时间步，我们计算

$$\delta_{T}^{y}(j)=\frac{\partial J(\theta)}{\partial y_{T}(j)}\frac{\partial y_{T}(j)}{\partial v_{T}(j)}=(\tau_{T}(j)-y_{T}(j))g_{0}^{\prime}(v_{T}(j))$$

对于单元组 j = 1,2, ... ,L。这个误差项可以用向量表示如下：

$$\delta_{T}^{y}=(\tau_{T}-y_{T})\odot g_{0}^{\prime}(v_{T}),$$

其中是矩阵之间的逐元素哈达玛积。对于隐藏层，我们有：

$$\delta_{T}^{b}=-\sum_{i=1}^{L}\frac{\partial J}{\partial v_{T}(i)}\frac{\partial v_{T}(i)}{\partial b_{T}(i)}\frac{\partial b_{T}(j)}{\partial u_{T}(j)}=\sum_{i=1}^{L}\tilde{\sigma}_{T}^{y}(i)v_{b y}(i,j)f^{\prime}(u_{T}(j))$$

对于 j = 1,2, ... ,N。这个表达式也可以写成向量形式 h_T = V_T

y_T ⊙ f ′(u_T).

对于所有其他时间步 t = T−1,T−2, ... ,1，我们可以总结输出的误差为：

y_t = (t - y_t) ⊙ g′(v_t),

对于所有单元 j = 1,2, ... ,L。同样，对于隐藏单元，我们可以总结结果为

$$\delta_{t}^{b}=(\mathrm{W}^{T}\delta_{t+1}^{b}+V^{T}\delta_{t}^{y})\odot f^{\prime}(u_{t})$$

其中 t y 是时间 t 的输出层传播的，h_{t+1} 是时间步 t+1 的隐藏层传播的。

13.5.7.2 正则化理论 对于病态问题，正则化理论试图解决我们是否可以防止机器学习模型过拟合的问题，因此在深度学习中起着重要作用。

在 20 世纪初期，发现了线性算子方程形式的解 (Vapnik 2000)

Af = F

对于线性算子 A 和一组函数 f ∈ Γ，在任意函数空间 Γ 中

是不适定的。上述方程不适定意味着像将 F 更改为满足 kF−Fk <  的小偏差会导致 kf −f k 变大。在函数 R(f) = kAf−Fk2 的表达式中，如果函数 f 最小化函数 R(f)，则无法保证我们找到的是正确解的好近似，即使  → 0。

许多现实生活中的问题是不适定的，例如试图颠倒因果关系，一个很好的例子是从已知结果中找出未知原因。

即使这个问题是一对一映射（Vapnik 2000），它也是不适定的。

另一个例子是从数据中估计密度函数（Vapnik 2000）。在 20 世纪 60 年代，人们意识到，如果改为最小化正则化函数（Vapnik 2000）



$$R^{*}(f)=\| A f-F_{\delta}\ |^{2}+\gamma(\delta)\Omega(f)，$$

$$(13.8)$$

其中 (f) 是一个泛函，() 是一个常数，然后我们获得一系列解，这些解随着  → 0 收敛于正确解。在深度学习中，泛函中的第一项，R*(f)，将被成本函数替换，而正则化项取决于要优化的参数集。对于 L1 正则化

()(f) =

∑n i ∣ Wi ∣而对于 L2 正则化，这个项等于 2 ‖W‖2 (参见 Bishop 2006; Friedman 等人 n.d.)。

13.5.7.3 Dropout Dropout 是一种防止神经网络过拟合的正则化方法（Srivastava 等人，2014）。这种类型的正则化也是廉价的

(Goodfellow 等人，2016)，特别是在训练神经网络时。在训练过程中，dropout 从不同稀疏网络中抽取样本

(Srivastava 等人，2014)。在测试时，模型是所有稀疏网络所有预测的平均值的近似值，只是它是一个比训练期间使用的网络少得多的模型。如果我们有一个具有 L 个隐藏层的网络，则 l ∈ {1，...，L} 是每个层的索引。如果 z(l) 是第 l 层的输入，则 y(l) 是该层的输出，其中 y(0) = x 表示网络的输入。

让 W(l) 表示权重，b(l) 表示偏差，那么网络方程为：

$$\begin{array}{l}{{z_{i}^{(l+1)}=w_{i}^{(i+1)}y^{l}+b_{i}^{(l+1)}}}\\ {{y_{i}^{(l+1)}=f(z_{i}^{(l+1)}),}}\end{array}$$

$$(13.7)$$

i (13.7)

其中 f 是激活函数。Dropout 是一个因素，通过执行以下操作随机地摆脱每个层的一些输出 (Srivastava 等人，2014)：

r

(l)

j ∼ 伯努利分布(p)，

其中 * 表示逐元素相乘。

## 13.6 长短期记忆网络

LSTM 架构最初由 Hochreiter 和 Schmidhuber（1997）提出

如今广泛应用于由于其在准确建模数据中的短期和长期依赖性方面的优越性能。因此，我们选择了 LSTM

架构比普通的 RNN 网络更高级。

当使用 BPTT 计算梯度时，错误向后流动。

因为在 RNN 中每个时间步使用相同的权重，所以它的梯度依赖于相同的权重集，这会导致梯度要么无限增长，要么消失（Goodfellow 等人 2016；Hochreiter 和 Schmidhuber 1997；Pascanu 等人 2013）。在第一种情况下，权重会振荡；在第二种情况下，学习长时间滞后需要花费很长时间（Hochreiter 和 Schmidhuber 1997）。在梯度爆炸的情况下，有一种被称为裁剪梯度的解决方案（Pascanu 等人。

2013），由以下过程给出，其中 ∧g 是梯度， 是阈值，而 L 是损失函数。但是消失梯度问题似乎没有解决方案。

为了解决这个问题，Hochreiter 和 Schmidhuber（1997）引入了 LSTM 网络，类似于 RNN，但其中隐藏单元被记忆单元替换。LSTM 是对 RNN 中遇到的梯度消失和爆炸的优雅解决方案。LSTM 中的隐藏单元（图 13.3）是一个结构，它保存一个内部状态，并且有一个恒定权重的递归连接，使得梯度可以多次传递而不会爆炸或消失（Lipton 等人 n.d.）。

算法 1 梯度裁剪

̂g ← L

if | |̂g || ≥  then

̂g ←

| |̂g ||

̂g end if

![264_image_0.png](img/264_image_0.png)

LSTM 网络是一组具有递归连接的子网，称为内存块。每个块包含一个或多个自连接内存单元和三个乘法单元，称为输入、输出和遗忘门，它们分别支持单元的读取、写入和重置操作（Graves 2012）。门控单元控制梯度通过内存单元的流动，当关闭它们时，允许梯度在不变化的情况下无限传递，使得 LSTM 适用于学习长时间依赖性，从而克服了 RNN 遇到的梯度消失问题。我们更详细地描述 LSTM 单元的内部工作。内存单元由输入节点、输入门、内部状态、遗忘门和输出门组成。内存单元中的组件如下：

- 输入节点从输入层 xt 和时间 t−1 处的隐藏状态 ht−1 中获取激活。然后将输入馈送到激活函数中，可以是 tanh 或 sigmoid。

- 输入门使用一个 sigmoid 单元，它从当前数据 xt 和时间步 t−1 处的隐藏单元获取输入。输入门将输入节点的值相乘，并且因为它是一个范围在零和一之间的 sigmoid 单元，它可以控制它所乘的信号的流动。

- 内部状态与单位权重具有自回归连接，也称为 Hochreiter 和 Schmidhuber（1997）中的常量错误旋转木马，并且由 s t = gt ⊙ it +ft ⊙ st−1 给出。Hadamard 乘积表示逐元素乘积，ft 是遗忘门（见下文）。

- 遗忘门 ft 并不是 LSTM 模型的原始部分，而是由 Gers 等人在 2000 年引入的。遗忘门将时间步 t−1 的内部状态乘以，以此方式可以清除过去的所有内容，如上述列表项中的方程所示。

- 内存单元的输出由内部状态 sc 乘以输出门 oc 得到。通常，内部状态会通过 tanh 激活函数运行。

LSTM 网络的方程可以总结如下。与之前一样，让 g 表示内存单元的输入，i 表示输入门，f 表示遗忘门，o 表示输出门，(参见图 13.4)

$$g_{t}=\varphi(W^{g X}x_{t}+W^{g b}h_{t-1}+b_{g})$$

$$(13.13)$$

gt = (WgXxt + *Wghht*−1 + bg) (13.13)

$\delta_{t}=\varphi(\,W^{i\!X}\,x_{t}+\,W^{i\!b}\,h_{t-1}+\,b_{i})$  $i_{t}=\sigma(\,W^{i\!X}x_{t}+\,W^{i\!b}h_{t-1}+\,b_{i})$  $i_{t}=\varphi(\,W^{i\!X}\,x_{t}+\,W^{i\!b}h_{t-1}+\,b_{i})$

$$(13.14)$$

$$f_{t}=\sigma(W^{f X}x_{t}+W^{f h}b_{t-1}+b_{f})$$ $$o_{t}=\sigma(W^{o X}x_{t}+W^{o b}b_{t-1}+b_{o})$$

$$(13.1S)$$

ft = (WfXxt + *Wfhht*−1 + bf ) (13.15)

$$(13.16)$$

ot = (WoXxt + *Wohht*−1 + bo) (13.16)

$s_{t}=g_{t}\odot i_{t}+s_{t-1}\odot f_{t}$  $h_{t}=\phi(s_{t})\odot o_{t}$.

$$(13.17)$$

$$(13.18)$$

其中哈达玛积表示逐元素相乘。在方程中，ht 是时间 t 的隐藏层的值，而 ht−1 是时间 t−1 时隐藏层中每个记忆单元的输出。权重 {*WgX,WiX,WfX,WoX*} 分别表示输入 xt 与输入节点、输入门、遗忘门和输出门之间的连接。同样地，{*Wgh,Wih,Wfh,Woh*} 表示隐藏层与输入节点、输入门、遗忘门和输出门之间的连接。每个单元组件的偏置项由下式给出

{*bg,bi,bf,bo*}.

![265_image_0.png](img/265_image_0.png)

## 13.7 Financial Model

本工作的目标是预测标普 500 指数中 50 支股票的收益。作为模型的输入，我们使用了直到时间 t 的股票收益和模型的预测，即一个 LSTM，其输出是时间 t+1 的股票收益。模型的预测帮助我们在时间 t 决定买入、持有或卖出哪些股票。这样，我们就有了一个自动化的交易策略。对于股票 i，我们使用直到时间 t 的历史收益来预测时间 t+1 的收益。

## 13.7.1 Return Series Construction

The returns are computed as:



$$R_{t+1}^{i}={\frac{P_{t+1}^{i}}{P_{t}^{i}}}-1$$

其中 Pt i 表示时间 t 的股票或商品 i 的价格，而 Rt i+1 表示其在时间 t+1 的收益。我们的深度学习模型然后尝试学习一个函数 G(⋅)，以预测参数集合 t+1 时的收益：

Rti+1 = G(Rt, Rt−1*, ...,* Rt−k)

其中 k 是历史收益向后推移的时间步数。

我们使用 30 个每日收益的滚动窗口来预测第 31 天的收益。 这个过程生成了 30 个连续一天收益的序列

{Rit−29, Rit−28*, ...,* Rit

},其中对于所有股票 i，t≥30。

## 13.7.2 模型评估

通过使用深度学习进行投资的一个解决方案是构建一个分类器，其中类 0 表示负收益，类 1 表示正收益。 但是，在我们的实验中，我们观察到，使用回归比使用纯分类给出了更好的结果。 在学习我们的模型时，我们使用均方误差（MSE）损失作为目标函数。 首先，在模型用验证集进行训练和验证后，我们对一个独立的测试集进行了预测，或者在这里我们称之为实时数据集。 这些预测是针对我们的股票收益的目标系列进行测试的（请参见实验 1 和 2），使用了称为命中率的正确性度量。 与李和尤（2017 年）一致，我们选择 HR 作为度量模型与实际股票收益结果相比预测结果的准确性的度量标准。 HR 定义为：

$$H R={\frac{1}{N}}\sum_{t=1}^{N}U_{t}$$

其中 N 是交易日的总数，Ut 定义为：

$$U_{t}=\left\{\begin{array}{l l}{{1\,如果\,R_{t}{\widehat{R}}_{t}}}\\ {{0\,否则}}\end{array}\right.$$

其中 Rt 是实现的股票收益，R

̂t 是第 t 个交易日的预测股票收益。 因此，HR 是根据实际目标系列测量的正确预测率。 通过使用 HR 作为差异的度量，我们可以得出结论，预测要么与实时目标收益移动在同一方向，要么与相反方向移动。 如果 HR 等于 1，则表示完全相关性，而值为零表示预测和实际系列移动在相反方向。 HR > 0.50 的值表示模型正确的概率超过 50％，而 HR ≤ 0.50 的值表示模型猜测结果。

我们使用 Python 进行计算，以及 Keras 和 PyTorch 深度学习库。 Keras 和 PyTorch 使用具有强大 GPU 加速的张量。 GPU 计算既在 NVIDIA GeForce GTX 1080 Ti 上进行，也在 NVIDIA GeForce GTX 1070 GDDR5 卡上进行。

在两台单独的机器上使用了 GeForce GTX 1070 GDDR5 卡。

## 13.7.3 数据和结果

我们进行了两种类型的实验。 第一种旨在演示 LSTM 使用一次一个股票作为输入直到时间 t，以及目标相同股票在时间 t+1 的预测能力。 从现在开始我们将其称为实验 1。

第二个实验旨在同时预测所有股票的收益。

这意味着我们所有 50 个股票的收益直到时间 t 都被输入到 LSTM 中

这个模型是训练来预测 t+1 时刻的 50 只股票回报率。除了这 50 只股票外，我们还向模型提供了原油期货、白银和黄金的回报率。

我们称之为实验 2。本章中使用的所有股票都来自标准普尔 500 指数，而商品价格则来自数据提供商 Quandl（Quandl n.d.）。

## 13.7.3.1 实验 1

13.7.3.1.1 主要实验 对于实验 1，我们的模型将时间 t 之前的股票回报率作为输入，一个接一个地预测时间 t+1 的相同回报率 - 请参阅上面关于回报序列构建的讨论。为每支股票训练了一个新模型。大多数参数在每支股票的训练过程中都保持不变。学习率设置为 0.001，我们使用了 0.01 的 dropout 率，唯一的例外是隐藏单元的数量。对于不同的股票，隐藏单元的数量是不同的。对于每支股票，我们从具有 100 个隐藏单元的 LSTM 开始，并增加该数量，直到满足条件 HR > 0.70，每次迭代增加 50 个单位，直到 200 个隐藏单元。

请注意，条件 HR > 0.70 从未满足，但这个值仅仅是为了保持计算的运行直到找到最佳值而选择的。在大多数情况下，我们运行了最多 400 个时期的实验，但如果测试误差没有改善或者测试误差增加，我们就会停止。这种技术称为提前停止。对于提前停止，我们在停止训练之前最多使用 50 个时期。训练是以 512 个样本的批次进行的。

由于我们为不同的股票训练了不同的 LSTM，因此我们获得了不同数量的数据用于训练、测试和验证模型。有时我们将测试数据称为实时数据。首先将数据分为 90%和 10%，其中 10%用于测试（实时数据），对应于最近的股票价格。然后将 90%的部分再次分为 85%和 15%，分别用于训练和验证。数据集的数据点和周期数在附录中的表 13.A.1 中给出。为了优化，我们测试了 RMSProp 和 Adam 两种算法，但发现最佳结果是使用随机梯度下降和动量。这仅在一次处理一个时间序列时才成立。对于实验 2，我们使用了 Adam 优化算法。实验 1 的结果如表 13.1 所示。

13.7.3.1.2 基准实验 LSTM 模型与另外两个模型进行了比较。基准模型是支持向量机（SVM）（Friedman et al. n.d.）

和一个神经网络（NN）。 NN 由一个隐藏层组成，隐藏单元的数量是使用与 LSTM 相同的过程选择的，唯一的区别是选择隐藏单元的范围在 50-150 之间。此外，我们使用了与 LSTM 相同的学习率、迭代次数、批量大小和丢失率。对于 NN，我们在回归设置中使用 MSE 训练模型。对于 NN 产生的预测，我们在实时数据集上计算了 HR。结果与 LSTM 的结果一起呈现在表 13.1 中。

通过检查表 13.1，我们可以得到以下数据。 LSTM 在 50 只股票中有 43 只股票的 HR > 0.50，而对于剩下的 7 只股票，它的表现不如随机（HR ≤0.50）。 SVM 对 21 只股票做出了“正确”的预测（HR >0.50），而 NN

只有 27 只股票的表现与真实序列的方向相同。如果我们假设通过四舍五入可以实现 HR = 0.51，那么这些值也可能是由于偶然性而实现的。 LSTM 对 10 只股票的 HR 值为 0.51，SVM 对 3 只股票，而 NN 对 8 只股票。即使 LSTM 似乎优于其他模型，但在性能上的差异并不大，除了一些情况。在某些股票上，SVM 和 NN 都可以与 LSTM 一样好甚至更好。但这个实验表明，LSTM 在预测其预测结果与真实序列的方向一致方面是一致的。

13.7.3.2 实验 2 在这个实验中，我们使用了所有 50 只股票的回报率。此外，我们使用了过去 30 天的石油、黄金和标普 500 指数的回报率作为输入。

我们模型的输出是对 50 只股票回报率的预测。为了测试 LSTM 的稳健性，我们还针对一个基准模型进行了实验，该模型由一种适用于回归的 SVM（Friedman 等人，无日期）组成。为了测试 LSTM 的盈利能力，我们在一个由我们最初的股票（见表 13.4）和标普 500 指数、石油和黄金的回报序列组成的较小投资组合上进行了实验。这部分实验旨在表明 LSTM 在其预测独立于时间段时是一致的。特别是我们对看到模型是否对次级房贷危机具有稳健性感兴趣。这些结果显示在表 13.5 中。

由于这一部分包含许多实验，我们在主要实验子部分中展示了对 50 只股票加商品进行的实验。基准实验在上面的子部分中呈现，最后一个实验针对不同市场环境的时间段在下面的“不同市场环境中的结果”子部分中呈现。

13.7.3.2.1 主要实验 在这个实验中，所有特征都使用最小-最大公式进行了缩放：

x0 = Δ x ⋅ (b − a) + a，

| 和 NN 股票 | 隐藏单元 | HR LSTM | HR SVM | HR NN |
| --- | --- | --- | --- | --- |
| AAPL | 150 | 0.53 | 0.52 | 0.52 (130) |
| MSFT | 100 | 0.51 | 0.49 | 0.49 (150) |
| FB | 100 | 0.58 | 0.58 | 0.56 (90) |
| AMZN | 100 | 0.55 | 0.56 | 0.53 (90) |
| JNJ | 100 | 0.52 | 0.47 | 0.50 (50) |
| BRK/B | 150 | 0.51 | 0.51 | 0.51 (50) |
| JPM | 100 | 0.52 | 0.51 | 0.50 (90) |
| XOM | 100 | 0.52 | 0.52 | 0.49 (50) |
| GOOGL | 100 | 0.54 | 0.53 | 0.53 (70) |
| GOOG | 100 | 0.55 | 0.55 | 0.55 (50) |
| BAC | 100 | 0.47 | 0.50 | 0.59 (50) |
| PG | 100 | 0.50 | 0.50 | 0.50 (110) |
| T | 150 | 0.52 | 0.48 | 0.50 (70) |
| WFC | 150 | 0.51 | 0.47 | 0.50 (70) |
| GE | 100 | 0.51 | 0.50 | 0.50 (110) |
| CVX | 150 | 0.50 | 0.53 | 0.50 (70) |
| PFE | 100 | 0.49 | 0.49 | 0.49 (50) |
| VZ | 150 | 0.51 | 0.53 | 0.50 (50) |
| CMCSA | 150 | 0.54 | 0.49 | 0.50 (110) |
| UNH | 100 | 0.52 | 0.48 | 0.52 (130) |
| V | 100 | 0.59 | 0.51 | 0.55 (70) |
| C | 150 | 0.52 | 0.50 | 0.51 (50) |
| PM | 100 | 0.56 | 0.56 | 0.52 (110) |
| HD | 100 | 0.53 | 0.50 | 0.53 (70) |
| KO | 150 | 0.51 | 0.48 | 0.50 (70) |
| MRK | 200 | 0.54 | 0.49 | 0.50 (110) |
| PEP | 100 | 0.55 | 0.52 | 0.51 (50) |
| INTC | 150 | 0.53 | 0.45 | 0.51 (110) |
| CSCO | 100 | 0.51 | 0.48 | 0.50 (90) |
| ORCL | 150 | 0.52 | 0.48 | 0.50 (130) |
| DWDP | 150 | 0.51 | 0.48 | 0.50 (90) |
| DIS | 150 | 0.53 | 0.49 | 0.52 (130) |
| BA | 100 | 0.54 | 0.53 | 0.51 (50) |
| AMGN | 100 | 0.51 | 0.52 | 0.53 (90) |
| MCD | 150 | 0.55 | 0.48 | 0.52 (130) |
| MA | 100 | 0.57 | 0.57 | 0.55 (130) |
| IBM | 100 | 0.49 | 0.49 | 0.50 (50) |
| MO | 150 | 0.55 | 0.47 | 0.52 (50) |
| MMM | 100 | 0.53 | 0.46 | 0.52 (90) |
| ABBV | 100 | 0.60 | 0.38 | 0.41 (110) |
| WMT | 100 | 0.52 | 0.50 | 0.51 (50) |
| MDT | 150 | 0.52 | 0.49 | 0.50 (50) |
| GILD | 100 | 0.50 | 0.52 | 0.51 (70) |
| CELG | 100 | 0.51 | 0.52 | 0.50 (90) |
| HON | 150 | 0.55 | 0.46 | 0.52 (130) |
| NVDA | 100 | 0.56 | 0.55 | 0.54 (90) |
| AVGO | 100 | 0.57 | 0.57 | 0.51 (130) |
| BMY | 200 | 0.52 | 0.49 | 0.50 (50) |
| PCLN | 200 | 0.54 | 0.54 | 0.53 (70) |
| ABT | 150 | 0.50 | 0.47 | 0.50 (70) |
| | | | |   |
| 结果是根据独立的实时数据集计算的。NN 列中括号中的数字代表隐藏单元的数量。 | | | | |

Δx = x − min(x)

max(x) − min(x)

, 而 a, b 是特征的范围 (a,b)。通常将 a 设为 0，b 设为 1。训练数据包括从 2014-05-13 到 2016-08-01 的 560 天。我们使用了一个验证集，由从 2016-08-02 到 2016-11-25 的 83 天组成，用于选择元参数，以及一个测试集，由从 2016-11-28 到 2017-03-28 的 83 天组成。最后，我们使用了一个实时数据集，涵盖了从 2017-03-29 到 2017-09-05 的 111 天。

我们使用了一个具有一个隐藏层 LSTM 和 50 个隐藏单元的 LSTM。作为激活函数，我们使用了 ReLu；我们还使用了一个 dropout 率为 0.01 和一个批量大小为 32。

模型经过了 400 个周期的训练。Adam 优化器的参数为学习率为 0.001，1 = 0.9，2 = 0.999， = 10−9，并且衰减参数设置为 0.0。我们使用了 MSE 作为损失函数。

为了评估我们模型的质量，并尝试确定它是否具有投资价值，我们查看了“实时数据集”，这是最新的数据集。 这个数据集在训练过程中没有使用，可以被认为是一个独立的数据集。 我们使用实时数据进行预测，以评估我们的模型与真实目标回报相比有多少次是正确的。 命中率告诉我们，如果模型的预测与真实回报的方向相同。 为了评估模型的盈利能力，我们使用模型的预测构建了每日更新的投资组合，并计算了它们的平均每日回报。 一个典型的情景是我们在市场开盘前使用我们的 LSTM 模型为所有 50 支股票的每日回报进行预测。 根据预测的方向，正或负，如果 Rt i > 0，我们就对股票 i 开仓； 如果 Rt i < 0，我们可以选择对股票 i 开空仓（在这种情况下，我们称之为长-短期投资组合），或者不采取任何行动，如果我们拥有这些股票，我们可以选择保留它们（我们称之为长期投资组合）。 在市场收盘时，我们关闭所有仓位。 因此，对于长-短期投资组合，第 t 天的投资组合的每日回报为∑50 i=1 sign(R̂t) ⋅ Rt。

关于投资组合权重的绝对值，我们尝试了两种类似的、等权重的投资组合。 投资组合 1：在开始时，我们将相同比例的资金分配给每支股票进行投资，然后每支股票的回报独立累积，因此一个时期的投资组合回报是该时期每支股票的回报的平均值。 投资组合 2：投资组合每天重新平衡，即每天我们将相同比例的资金分配给每支股票进行投资，因此投资组合的每日回报是每支股票的每日回报的平均值。 每个投资组合都有一个长期和一个长-短期版本。 我们意识到不优化权重可能会导致我们的策略具有非常保守的回报特征。 实验 2 的结果在表 13.2 中呈现。

13.7.3.2.2 基线实验 这个实验首先旨在将 LSTM 与一个基线（在本例中是 SVM）进行比较，并且第二个目的是测试模型之间在用作 LSTM 输入的回望期方面的泛化能力。

对于 SVM 和 LSTM，我们注意到使用更长的历史回报序列作为输入时，LSTM 仍然保持稳健，并且我们没有看到过拟合现象，而 SVM 则不同。 SVM 在训练集上表现非常好，但在验证集和测试集上表现较差。 LSTM 和 SVM 都使用了滚动窗口的天数进行测试，窗口集合为：{1,2,5,10}。

| 表格 13.2 | 实验 2（主要实验） | | |
| --- | --- | --- | --- |
| 股票 | HR | Avg Ret %(L) | Avg Ret %(L/S) |
| 投资组合 1 | 0.63 | 0.18 | 0.27 |
| 投资组合 2 | 0.63 | 0.18 | 0.27 |
| AAPL | 0.63 | 0.24 | 0.32 |
| MSFT | 0.71 | 0.29 | 0.45 |
| FB | 0.71 | 0.31 | 0.42 |
| AMZN | 0.69 | 0.27 | 0.41 |
| JNJ | 0.65 | 0.12 | 0.19 |
| BRK/B | 0.70 | 0.19 | 0.31 |
| JPM | 0.62 | 0.22 | 0.38 |
| XOM | 0.70 | 0.11 | 0.25 |
| GOOGL | 0.72 | 0.31 | 0.50 |
| GOOG | 0.75 | 0.32 | 0.52 |
| BAC | 0.70 | 0.30 | 0.55 |
| PG | 0.60 | 0.60 | 0.90 |
| T | 0.61 | 0.80 | 0.22 |
| WFC | 0.67 | 0.16 | 0.38 |
| GE | 0.64 | 0.50 | 0.24 |
| CVX | 0.71 | 0.18 | 0.31 |
| PFE | 0.66 | 0.70 | 0.14 |
| VZ | 0.50 | 0.10 | 0.10 |
| CMCSA | 0.63 | 0.23 | 0.36 |
| UNH | 0.59 | 0.20 | 0.22 |
| V | 0.65 | 0.23 | 0.31 |
| C | 0.69 | 0.28 | 0.39 |
| PM | 0.64 | 0.17 | 0.28 |
| HD | 0.61 | 0.10 | 0.17 |
| KO | 0.61 | 0.80 | 0.90 |
| MRK | 0.61 | 0.90 | 0.16 |
| PEP | 0.60 | 0.80 | 0.11 |
| INTC | 0.63 | 0.16 | 0.31 |
| CSCO | 0.68 | 0.14 | 0.31 |
| ORCL | 0.52 | 0.80 | 0.40 |
| DWDP | 0.60 | 0.21 | 0.35 |
| DIS | 0.59 | 0 | 0.90 |
| BA | 0.57 | 0.23 | 0.16 |
| AMGN | 0.65 | 0.21 | 0.36 |
| MCD | 0.58 | 0.16 | 0.12 |
| MA | 0.66 | 0.25 | 0.34 |
| IBM | 0.54 | −0.40 | 0.60 |
| MO | 0.59 | 0.10 | 0.13 |
| MMM | 0.63 | 0.16 | 0.24 |
| ABBV | 0.61 | 0.18 | 0.22 |
| WMT | 0.50 | 0.14 | 0.16 |
| MDT | 0.59 | 0.90 | 0.17 |
| GILD | 0.50 | 0.16 | 0.11 |
| CELG | 0.64 | 0.28 | 0.45 |
| HON | 0.66 | 0.15 | 0.20 |
| NVDA | 0.68 | 0.54 | 0.68 |
| AVGO | 0.65 | 0.37 | 0.59 |
| BMY | 0.57 | 0.13 | 0.19 |
| PCLN | 0.61 | 0.14 | 0.24 |
| ABT | 0.63 | 0.21 | 0.28 |
| | | | |
| HR，长期投资组合（L）和多空投资组合（L/S）的平均每日收益率（以百分比表示）。结果是 | | |   |

HR，长期投资组合（L）和多空投资组合（L/S）的平均每日收益率（以百分比表示）。结果是

计算得出的独立实时数据集。

| Model | HR | Avg Ret %(L) | Avg Ret %(L/S) |
| --- | --- | --- | --- |
| LSTM (1) | 0.59 | 0.14 | 0.21 |
| LSTM (2) | 0.61 | 0.17 | 0.26 |
| LSTM (5) | 0.62 | 0.17 | 0.26 |
| LSTM (10) | 0.62 | 0.17 | 0.26 |
| SVM (1) | 0.59 | 0.14 | 0.21 |
| SVM (2) | 0.58 | 0.13 | 0.18 |
| SVM (5) | 0.57 | 0.12 | 0.16 |
| SVM (10) | 0.55 | 0.11 | 0.14 |
| 表格显示了每个模型的 HR 和每日平均回报；所有计算都是在 | | |   |

表格显示了每个模型的 HR 和每日平均回报；所有计算都是在样本外的实时数据集上进行的。模型名称中括号中的数字表示回报序列的回顾长度，即交易日数。

基准实验的结果如表 13.3 所示。从结果可以看出，LSTM 在 HR 和每日平均回报上的表现都有所提升，无论是长期还是长短期投资组合。对于 SVM 来说，情况正好相反，即只有考虑最近的历史数据时，SVM 与 LSTM 相比才可比拟。我们使用的历史数据越多，SVM 在所有指标中的表现就越差，无论是长期还是长短期投资组合的 HR 和每日平均回报。这表明，随着我们向后看的时间窗口变长，SVM 对训练数据的过度拟合程度越来越严重，而 LSTM 保持稳健。

13.7.3.2.3 不同市场环境下的结果为了验证此实验的结果，我们在投资组合 1 上进行了另一个实验。这一次，我们不是使用全部 50 只股票作为模型的输入和输出，而是挑选了 40 只股票。与之前一样，在此投资组合中加入了标准普尔 500、石油和黄金的回报序列。数据分为训练集 66%、验证集（1）11%、验证集（2）11%、实时数据集 11%。用于此投资组合的股票列在表 13.4 中，结果显示在表 13.5 中。请注意，投资组合的表现（夏普比率）在金融危机前期（2005-2008 年）达到了顶峰，但在危机期间出现下滑，尽管仍有

| AAPL | MSFT US | AMZN US Equity | JNJ US |
| --- | --- | --- | --- |
| BRK/B | JPM | XOM | BAC |
| PG | T | WFC | GE |
| CVX | PFE | VZ | CMCSA |
| UNH | C | HD | KO |
| MRK | PEP | INTC | CSCO |
| ORCL | DWDP | DIS | BA |
| AMGN | MCD | IBM | MO |
| MMM | WMT | MDT | GILD |
| CELG | HON | BMY | ABT |
| 用于第二部分实验的 40 只股票。 | | |   |
| 平均回报 | 平均回报 | 夏普比率 | 夏普比率 | | | | 训练期 | HR % | % (L) | % (L/S) | ratio (L) | ratio (L/S) |
| 2000–2003 | 49.7 | −0.05 | −0.12 | −0.84 | −1.60 |
| 2001–2004 | 48.1 | 0.05 | −0.02 | 2.06 | −0.73 |
| 2002–2005 | 52.5 | 0.11 | 0.10 | 6.05 | 3.21 |
| 2003–2006 | 55.9 | 0.10 | 0.16 | 5.01 | 5.85 |
| 2004–2007 | 54.0 | 0.14 | 0.12 | 9.07 | 5.11 |
| 2005–2008 | 61.7 | 0.26 | 0.45 | 7.00 | 9.14 |
| 2006–2009 | 59.7 | 0.44 | 1.06 | 3.10 | 6.22 |
| 2007–2010 | 53.8 | 0.12 | 0.12 | 5.25 | 2.70 |
| 2008–2011 | 56.5 | 0.20 | 0.26 | 6.12 | 6.81 |
| 2009–2012 | 62.8 | 0.40 | 0.68 | 6.31 | 9.18 |
| 2010–2013 | 55.4 | 0.09 | 0.14 | 3.57 | 3.73 |
| 2011–2014 | 58.1 | 0.16 | 0.21 | 5.59 | 6.22 |
| 2012–2015 | 56.0 | 0.15 | 0.21 | 5.61 | 5.84 |
| 这个表格显示了长（L）投资组合的 HR，平均每日收益，以及长-空（L/S）投资组合的平均每日收益 | | | | |   |

表格 13.5 实验 2（不同市场制度的结果）

这个表格显示了长（L）投资组合的 HR，平均每日收益，以及长-空（L/S）投资组合的平均每日收益。

以及它们各自的夏普比率（L）和（L/S）。结果是针对独立的实时数据集计算的。

每个三年周期分为 66% 的训练集，11% 的验证集（1），11% 的验证集（2）和 11% 的实时集。

这是一个相当高的表现。这些实验是在没有交易成本的情况下进行的，我们仍然假设我们可以在没有任何市场摩擦的情况下买卖，而在现实中，在金融危机期间可能是不可能的。

LSTM 网络训练周期为三年，对实时数据的测试是在训练和验证期之后进行的。这个实验意图展示的是，LSTM 网络能够帮助我们选择具有非常高夏普比率的投资组合，而不受回测中选择的时间段的影响。这意味着 LSTM 的良好性能不仅仅是在股市处于繁荣时期的一时运气。

## 13.8 结论

深度学习已经被证明是在多个领域（如计算机视觉和自然语言处理）中建模非结构化数据的最成功的机器学习模型之一。深度学习通过引入用其他更简单的表示来表达的表示来解决表示学习中的核心问题。深度学习允许计算机通过组合更简单的概念来构建复杂的概念。深度学习系统可以通过结合诸如角和轮廓之类的更简单的概念来表示一个人的图像的概念，这些概念又是通过边缘来定义的。

学习为数据找到正确的表示提供了对深度学习的一种视角。你可以将其看作是第一层次“发现”了允许高效降维和进行非线性建模的特征。

深度学习的另一个视角是，深度使计算机能够学习多步计算机程序。表示的每一层可以被认为是在并行执行另一组指令后计算机内存的状态。

深度更大的网络可以按顺序执行更多的指令。顺序指令提供了很大的力量，因为后续指令可以参考先前指令的结果。

卷积神经网络用于图像处理，循环神经网络用于自然语言处理在金融领域以及其他科学领域中的应用越来越多。

为这些深度模型付出的代价是需要学习的大量参数、进行非凸优化和可解释性。研究人员在不同的背景下找到了执行任务的正确模型，这些模型具有很高的准确性、达到稳定性、避免过度拟合并改善这些模型的可解释性。

金融是一个领域，在这个领域中，由于金融从业者和研究人员可以利用大量的结构化和非结构化数据，这些好处可以得到利用。

在本章中，我们探讨了时间序列的一个应用。鉴于时间序列中存在自相关、周期性和非线性，LSTM 网络是金融时间序列建模的一个合适选择。Elman 神经网络也是这个任务的一个很好的选择，但是 LSTMs 在其他非金融应用中已被证明更好。时间序列还表现出其他具有挑战性的特征，如估计和非平稳性。

我们已经在单变量环境中测试了 LSTM。LSTM 网络的表现优于 SVM 和 NN - 见实验 1。尽管性能差异不是很重要，但 LSTM 在其预测中表现一致。

我们具有外生变量的多变量 LSTM 网络实验显示，在不同市场环境中，与 AR 模型相比，与 VAR 模型相比，其线性对应物，表现良好的性能。在我们的实验中，LSTMs 在我们的等权重长仓组合和无约束组合中显示出更好的准确率、命中率和高夏普比率。

这些比率在样本内和样本外都表现良好。我们组合实验的夏普比率为长仓组合为 8，多头-空头版本为 10，使用 2014 年至 2017 年的模型的等权重组合提供了 2.7 的夏普比率。结果显示，在不同市场环境中使用相同的建模方法时具有一致性。未考虑交易成本。

我们可以得出结论，LSTM 网络是金融时间序列中一种有前景的建模工具，特别是具有外生变量的多变量 LSTM 网络。这些网络可以使金融工程师建模时间依赖性、非线性、具有非常灵活的模型的特征发现，这些模型可能能够抵消金融中具有挑战性的估计和非平稳性以及过度拟合的潜力。在金融领域，这些问题永远不容忽视，尤其是在具有大量参数、非线性和难以解释的模型，如 LSTM 网络中。

我们认为金融工程师应该纳入深度学习，不仅用于对非结构化数据进行建模，还用于对结构化数据进行建模。我们面前有着有趣的建模时代。

## 附录 A

表 13.A.1 实验 1 中训练集、测试集和实时数据集的时期

| 股票 | 训练期 | 测试期 | 实时期 |
| --- | --- | --- | --- |
| AAPL | 1982-11-15 2009-07-08 (6692) | 2009-07-09 2014-03-18 (1181) | 2014-03-19 2017-09-05 (875) |
| MSFT | 1986-03-17 2010-04-21 (6047) | 2010-04-22 2014-07-17 (1067) | 2014-07-18 2017-09-05 (791) |
| FB | 2012-05-21 2016-06-20 (996) | 2016-06-21 2017-03-02 (176) | 2017-03-03 2017-09-05 (130) |
| AMZN | 1997-05-16 2012-12-07 (3887) | 2012-12-10 2015-08-31 (686) | 2015-09-01 2017-09-05 (508) |
| JNJ | 1977-01-05 2008-02-20 (7824) | 2008-02-21 2013-08-14 (1381) | 2013-08-15 2017-09-05 (1023) |
| BRK/B | 1996-05-13 2012-09-11 (4082) | 2012-09-12 2015-07-24 (720) | 2015-07-27 2017-09-05 (534) |
| JPM | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| XOM | 1980-07-30 2008-12-19 (7136) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| GOOGL | 2004-08-20 2014-08-25 (2490) | 2014-08-26 2016-05-23 (439) | 2016-05-24 2017-09-05 (325) |
| GOOG | 2014-03-31 2016-11-22 (639) | 2016-11-23 2017-05-08 (113) | 2017-05-09 2017-09-05 (84) |
| BAC | 1980-07-30 2008-12-19 (7134) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| PG | 1980-07-30 2008-12-19 (7136) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| T | 1983-11-23 2009-10-02 (6492) | 2009-10-05 2014-04-24 (1146) | 2014-04-25 2017-09-05 (849) |
| WFC | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| GE | 1971-07-08 2006-11-06 (8873) | 2006-11-07 2013-01-29 (1566) | 2013-01-30 2017-09-05 (1160) |
| CVX | 1980-07-30 2008-12-19 (7136) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| PFE | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| VZ | 1983-11-23 2009-10-02 (6492) | 2009-10-05 2014-04-24 (1146) | 2014-04-25 2017-09-05 (849) |
| CMCSA | 1983-08-10 2009-09-09 (6549) | 2009-09-10 2014-04-14 (1156) | 2014-04-15 2017-09-05 (856) |
| UNH | 1985-09-04 2010-03-08 (6150) | 2010-03-09 2014-06-27 (1085) | 2014-06-30 2017-09-05 (804) |
| V | 2008-03-20 2015-06-26 (1800) | 2015-06-29 2016-09-29 (318) | 2016-09-30 2017-09-05 (235) |
| C | 1986-10-31 2010-06-14 (5924) | 2010-06-15 2014-08-08 (1046) | 2014-08-11 2017-09-05 (775) |
| PM | 2008-03-19 2015-06-26 (1801) | 2015-06-29 2016-09-29 (318) | 2016-09-30 2017-09-05 (235) |
| HD | 1981-09-24 2009-03-31 (6913) | 2009-04-01 2014-02-04 (1220) | 2014-02-05 2017-09-05 (904) |
| KO | 1968-01-04 2006-01-13 (9542) | 2006-01-17 2012-09-20 (1684) | 2012-09-21 2017-09-05 (1247) |
| MRK | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| PEP | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| INTC | 1982-11-15 2009-07-08 (6692) | 2009-07-09 2014-03-18 (1181) | 2014-03-19 2017-09-05 (875) |
| CSCO | 1990-02-20 2011-03-24 (5287) | 2011-03-25 2014-12-08 (933) | 2014-12-09 2017-09-05 (691) |
| ORCL | 1986-04-16 2010-04-29 (6032) | 2010-04-30 2014-07-22 (1064) | 2014-07-23 2017-09-05 (788) |
| DWDP | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| DIS | 1974-01-07 2007-06-06 (8404) | 2007-06-07 2013-04-26 (1483) | 2013-04-29 2017-09-05 (1099) |
| BA | 1980-07-30 2008-12-19 (7136) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| AMGN | 1984-01-04 2009-10-13 (6473) | 2009-10-14 2014-04-29 (1142) | 2014-04-30 2017-09-05 (846) |
| MCD | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| MA | 2006-05-26 2015-01-23 (2149) | 2015-01-26 2016-07-26 (379) | 2016-07-27 2017-09-05 (281) |
| IBM | 1968-01-04 2006-01-13 (9541) | 2006-01-17 2012-09-20 (1684) | 2012-09-21 2017-09-05 (1247) |
| MO | 1980-07-30 2008-12-19 (7134) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| MMM | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| ABBV | 2012-12-12 2016-08-05 (888) | 2016-08-08 2017-03-22 (157) | 2017-03-23 2017-09-05 (116) |
| WMT | 1972-08-29 2007-02-09 (8664) | 2007-02-12 2013-03-08 (1529) | 2013-03-11 2017-09-05 (1133) |
| MDT | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| GILD | 1992-01-24 2011-09-07 (4912) | 2011-09-08 2015-02-19 (867) | 2015-02-20 2017-09-05 (642) |
| CELG | 1987-09-02 2010-08-27 (5755) | 2010-08-30 2014-09-11 (1016) | 2014-09-12 2017-09-05 (752) |
| HON | 1985-09-23 2010-03-11 (6139) | 2010-03-122014-06-30 (1083) | 2014-07-01 2017-09-05 (803) |
| NVDA | 1999-01-25 2013-05-03 (3562) | 2013-05-06 2015-10-29 0(466) | 2015-10-30 2017-09-05 (466) |
| AVGO | 2009-08-07 2015-10-22 (1533) | 2015-10-23 2016-11-17 (271) | 2016-11-18 2017-09-05 (200) |
| BMY | 1980-07-30 2008-12-18 (7135) | 2008-12-19 2013-12-19 (1259) | 2013-12-20 2017-09-01 (933) |
| PCLN | 1999-03-31 2013-05-20 (3527) | 2013-05-21 2015-11-05 (622) | 015-11-06 2017-09-05 (461) |
| ABT | 1980-07-30 2008-12-19 (7135) | 2008-12-22 2013-12-20 (1259) | 2013-12-23 2017-09-05 (933) |
| | | | |

括号内显示了每个数据集中的交易日数。

## 参考资料

Bengio, S., Vinyals, O., Jaitly, N., Shazeer, N. n.d. *Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks*. Google Research, Mountain View, CA, USA

bengio,vinyals,ndjaitly,noam@google.com.

Bianchi, F. M., Kampffmeyer, M., Maiorino, E., Jenssen, R. (未来日期). Temporal Overdrive Recurrent Neural Network, arXiv preprint arXiv:1701.05159.

Bishop, C.M. (2006). *模式识别和机器学习*。Springer Science, Business Media, LLC。ISBN: 10: 0-387-31073-8，13: 978-0387-31073-2。

Cai, X., Zhang, N., Venayagamoorthy, G.K., and Wunsch, D.C. (2007). 用混合 PSO-EA 算法训练的递归神经网络进行时间序列预测。 *神经计算* 70 (13–15): 2342–2353。ISSN 09252312。https://doi.org/10.1016/j.neucom.2005.12.138。

Elman, J.L. (1995). 语言作为动态系统。在：Mind as motion: Explorations in the dynamics of cognition (ed. T. van Gelder and R. Port)，195–223 页。MIT Press。

Fischer, T. and Krauss, C. *用于金融市场预测的长短期记忆网络的深度学习*。Friedrich-Alexander-Universität Erlangen-Nürnberg, 经济学研究所。ISSN: 1867-6767。www.iwf.rw.fau.de/research/iwf-discussion-paper-series/。

Friedman, J.; Hastie, T.; Tibshirani, R.. *统计学习的要素，数据挖掘，推理和预测*。2008 年 9 月 30 日。

Gers, F.A., Schmidhuber, J., and Cummins, F. (2000). 学习遗忘：LSTM 的持续预测。 *神经计算* 12 (10): 2451–2471.

Goodfellow, I., Bengio, Y., and Courville, A. (2016). *深度学习*。MIT Press，www.deep learningbook.org。

Graves, A. (2012). *使用递归神经网络进行监督序列标记*。

Springer-Verlag Berlin Heidelberg。ISBN: 978-3642-24797-2。

Haykin, S. (2009). *神经网络和学习机器*，第 3 版。Pearson, Prentice Hall。ISBN:

13 : 978-0-13-147139-9, 10 : 0-13-147139-2.

Hochreiter, S. and Schmidhuber, J. (1997). 长短期记忆。 *神经计算* 9:

1735–1780. ©1997 麻省理工学院.

Lee, S.I. and Yoo, S.J. (2017). 用于最佳投资的深度高效前沿方法。 *应用专家系统*.

Lipton, Z.C., Berkowitz, J.; Elkan, C.. *序列学习的递归神经网络的关键评论*。arXiv:1506.00019v4 [cs.LG] 2015 年 10 月 17 日。

Mokolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J.. Google Inc. Mountain View. *单词和短语及其组合性的分布表示* ArXiv;1310.4546v1 [cs.CL] 2013 年 10 月 16 日。

Mori, H.M.H. and Ogasawara, T.O.T. (1993). 用于短期负荷预测的递归神经网络。在：*1993 年国际应用神经网络论坛论文集*，第 31 卷，276–281 页。https://doi.org/10.1109/ANN.1993

.264315.

Ogata, T., Murase, M., Tani, J. 等人。 (2007). 递归神经网络实现复合句子和手臂运动的双向翻译。在：IROS 2007. IEEE/RSJ 国际智能机器人与系统会议，1858–1863 页。IEEE。

Pascanu, R., Mikolov, T.; Bengio, Y.. *训练递归神经网络的困难*。

第 30 届国际机器学习会议论文集，美国乔治亚州亚特兰大，2013 年。JMLR WandCP 卷 28。版权归作者所有，2013 年。

Qian，X。*金融系列预测：时间序列模型和*机器学习方法的精度比较。ArXiv：1706.00948v4 [cs.LG] 2017 年 12 月 25 日。

Quandl（无日期）。https://www.quandl.com

Schäfer，A.M.和 Zimmermann，H.-G.（2007 年）。循环神经网络是通用逼近器。*国际神经系统杂志*17（4）：253–263。https://doi.org/10.1142/

S0129065707001111。

Srivastava，N.，Hinton，G.，Krizhevsky，A.等（2014 年）。Dropout：防止神经网络过度拟合的简单方法。*机器学习研究杂志*15：1929–1958。

Sutskever，I。*训练循环神经网络：数据挖掘，推理和预测*。博士

论文，多伦多大学计算机科学系，2013 年。

Vapnik，V.N.（2000 年）。*统计学习理论的本质*，第二版。斯普林格科学，商业媒体纽约，公司。ISBN：978-1-4419-3160-3。

Yu，D.和 Deng，L.（2015 年）。*自动语音识别，深度学习方法*。伦敦：

斯普林格出版社。ISBN：978-1-4471-5778-6。ISSN 1860-4862。https://doi.org/10.1007/9781-4471-5779-3。

## 第一章

Michael Kollo 是 Rosenberg Equities 的副全球研究主管，专注于机器学习和大数据应用、因子研究和股票组合的定量策略。在加入 Rosenberg Equities 之前，Michael 曾担任 Renaissance Asset Management 的风险负责人，负责专门的新兴市场股票策略。在 Renaissance 之前，Michael 在 Fidelity 和 BlackRock 担任高级研究和投资组合管理职位。Michael 的经验涵盖了从风险建模到信号生成、投资组合管理和产品设计的因子投资。Michael 在伦敦的伦敦经济学院获得金融博士学位，并在澳大利亚新南威尔士大学获得学士和硕士学位。他在帝国理工学院讲课，并且是伦敦金融科技公司的积极导师。

## 第二章

Rado Lipuš，CFA，是 Neudata 创始人兼首席执行官，该公司是一家提供替代数据智能的提供商。在创立 Neudata 之前，Rado 的职业经验涵盖了 20 年的金融科技领导、销售管理和为买方提供数据创新。他曾在 MSCI（Barra）和 S&P Capital IQ 从事数年量化组合构建和风险管理工作，并为 CITE Investments 筹集资金。Rado 最近在伦敦的 PerTrac 担任董事总经理，该公司是欧洲、中东和亚洲对冲基金分配商和机构投资者的领先金融科技和数据分析解决方案提供商。他还在金融数据公司如 eVestment、2iQ Research、I/B/E/S 和 TIM Group 有经验。作为替代数据方面的承认专家，Rado 经常受邀在会议和行业活动上演讲。Rado 毕业于奥地利格拉茨大学获得工商管理硕士学位，并拥有 CFA 特许资格。

Daryl Smith，CFA，是 Neudata 的研究主管。他和他的团队负责为全球范围内的各种资产管理公司研究和发现替代数据集。在加入 Neudata 之前，Daryl 在精品投资公司 Liberum Capital 担任股票研究分析师，涉及农业、化工和多元金融等多个领域。在 Liberum 之前，他在高盛担任股票衍生品分析师和监管报告战略师。Daryl 拥有巴斯大学的机械工程硕士学位，并且是 CFA 牌照持有者。

## 第三章

Ekaterina Sirotyuk 是瑞士信贷的投资解决方案与产品投资组合经理，也是《技术驱动的投资》的首席作者，这是关于人工智能/大数据在投资管理中应用的部门报告。在 2014 年加入瑞士信贷之前，Ekaterina 曾是一家德国投资公司的经理，负责能源相关投资的获取和评估以及交易结构。在此之前，她在伦敦的美国银行美林担任过一名副手，从事固定收益、货币和商品部门的跨资产类结构，为欧洲的养老金基金和保险公司提供服务。Ekaterina 的职业生涯始于位于纽约和苏黎世的瑞银替代与量化投资部门的投资分析师。

她获得了伦敦大学（主校区 - 伦敦政治经济学院）的经济与管理学士学位（一等荣誉）和欧洲工商管理学院的工商管理硕士学位，她还在那里完成了金融学的博士课程。此外，Ekaterina 还是瑞士金融科技协会的领导者。

## 第四章

Vinesh Jha 是 ExtractAlpha 的首席执行官和创始人，该公司于 2013 年在香港成立，旨在为资本市场的新数据分析和营销带来严谨的分析能力。从 1999 年到 2005 年，Vinesh 在旧金山的 StarMine 担任量化研究总监，在那里他开发了行业领先的卖方分析师绩效指标，以及基于分析师、基本面和其他数据来源的成功商业 alpha 信号和产品。随后，他为纽约的美林和摩根士丹利的专有交易台开发了系统交易策略。最近，他在 PDT 担任执行董事。

Partners 是摩根士丹利旗下首个量化专有交易团队的子公司，Vinesh 在这里除了研究外，还将他在传达复杂量化概念方面的经验应用到投资者关系中。Vinesh 持有芝加哥大学的本科学位和剑桥大学的研究生学位，两者都是数学专业。

## 第五章

Saeed Amen 是 Cuemacro 的创始人。在过去的十年里，Saeed 在雷曼兄弟（Lehman Brothers）和野村证券（Nomura）等主要投资银行开发了系统化交易策略。此外，他还是一名独立的系统化外汇交易员，自 2013 年以来一直在交易流动性较强的 G10 外汇。他是《Trading Thalesians: What the Ancient World Can Teach Us About Trading Today》（Palgrave Macmillan, 2014）的作者。通过 Cuemacro，他现在为系统化交易领域的客户提供咨询和研究服务。Saeed 的客户包括主要的量化基金和数据公司，如 RavenPack 和 TIM Group。他还是 Thalesians 的联合创始人。Saeed 拥有伦敦帝国学院（Imperial College London）的数学与计算机科学硕士学位。

Iain J. Clark 是 Efficient Frontier Consulting Ltd 的董事总经理和创始人，这是一家独立的量化咨询公司，为银行、对冲基金、交易所和金融服务行业的其他参与者提供咨询和培训服务。

他专注于外汇（FX）、外汇/利率（FX/IR）和大宗商品，并且是波动率建模和将数值方法应用于金融领域的行业专家。Iain 在金融领域有着 14 年的经验，包括担任标准银行（Standard Bank）外汇和大宗商品量化分析主管、联合信用（UniCredit）和德累斯顿克莱因沃特（Dresdner Kleinwort）外汇量化分析主管；他还曾在雷曼兄弟（Lehman Brothers）、巴黎银行（BNP Paribas）和摩根大通（JP Morgan）工作过。他是《外汇期权定价：从业者指南》（Wiley, 2011）和《大宗商品期权定价：从业者指南》（Wiley, 2014）的作者。Iain 不仅是一位实战型量化技术专家，还是一位专业的量化模型师和策略顾问，具有丰富的 C++等语言实践经验。

（多线程、Boost、STL）、C\#、Java、Matlab、Python 和 R。

## 第六章

Giuliano De Rossi 是麦格理（Macquarie）欧洲量化研究团队的负责人，驻地伦敦。他从 PIMCO 加入，曾在信用和权益分析与资产配置团队担任分析师。在此之前，他在瑞银（UBS）的量化研究团队工作了六年。他拥有剑桥大学的经济学博士学位，并在加入金融行业全职工作前在剑桥担任经济学学院讲师三年。Giuliano 的硕士学位是来自伦敦政治经济学院（London School of Economics），他的本科学位是来自米兰的博科尼大学（Bocconi University）。

他曾就多个主题进行研究，包括配对交易、低波动率、全球 ETF 的跟踪误差、跨资产策略、下行风险和文本挖掘。他的学术研究发表在《计量经济学杂志》和《实证金融杂志》上。

Jakub Kolodziej 于 2014 年加入伦敦的欧洲量化研究团队，在此之前，他曾在一家量化对冲基金担任投资分析师。

他拥有伦敦政治经济学院的金融和私募股权硕士学位，以及华沙经济学院的金融和会计学学士学位。

Gurvinder Brar 是麦格理全球量化研究团队的全球负责人。全球量化研究团队包括 13 名分析师，团队在所有主要的股票市场地区运作。他们的目标是提供关于阿尔法、风险和组合构建问题的前沿、有针对性和可行性研究，并愿意与客户建立深度合作伙伴关系。地区团队密切合作，旨在建立一个共同的全球知识库，备有特定的本地专业知识。此外，该团队还为客户承担定制项目，协助投资过程的各个方面。

## 第七章

Tony Guida 是一名高级定量投资组合经理，在伦敦一家英国养老基金资产管理公司管理多因子股票组合。在此之前，Tony 曾担任 EDHEC RISK 的智能β和风险配置高级研究顾问。

Scientific Beta，为资产所有者提供构建和配置风险溢价的建议。在加入 EDHEC 之前，Tony 在 UNIGESTION 工作了八年，担任高级研究分析师。Tony 曾是最小方差策略研究和投资委员会的成员，并领导机构客户的因子投资研究小组。Tony 是《量化投资中的大数据和机器学习》（Wiley，2018）的编辑和合著者。他在法国萨瓦大学获得了经济计量学和金融学的学士和硕士学位。Tony 是关于量化投资现代方法的演讲者，并举办了几场关于“量化投资中的机器学习应用”的研讨会。

Guillaume Coqueret 自 2015 年起担任蒙彼利埃商学院金融助理教授。他拥有 ESSEC 的工商管理博士学位。

商学院。在担任 MBS 教授之前，他曾在 EDHEC 风险研究所担任高级定量研究分析师，从 2013 年到 2015 年。他在定量金融领域拥有两个硕士学位。他的工作已经发表在《银行与金融杂志》、《投资组合管理杂志》和《专家系统与应用》等期刊上。

## 第八章

Andy Moniz 是德意志银行的全球市场首席数据科学家。Andy 是自然语言处理方面的专家，此前曾在瑞士银行担任定量投资组合经理，负责瑞士银行的多空股票选择和宏观策略。

在瑞士银行担任 O'Connor 和系统性环境社会治理（ESG）策略的环境社会治理（ESG）策略。

利用会计信号和非结构化数据进行资产管理。在加入 UBS 之前，Andy 是荷兰国际退休金基金管理公司的高级量化投资组合经理，负责因子溢价、文本挖掘和 ESG 股票选择策略。Andy 于 2000 年在英格兰银行担任宏观经济学家开始他的职业生涯。2003 年至 2011 年期间，他在各投资银行从事量化股票交易。Andy 拥有剑桥大学经济学学士和硕士学位、伦敦大学统计学硕士学位以及荷兰鹿特丹伊拉斯姆斯大学的信息检索和自然语言处理博士学位。

## 第九章

Peter Hafez 是 RavenPack 的数据科学负责人。自 2008 年加入 RavenPack 以来，他一直是应用新闻分析领域的先驱，为世界顶级银行和对冲基金带来了另类数据见解。Peter 在量化金融方面拥有超过 15 年的经验，曾在标准普尔、瑞士信贷第一波士顿和萨克索银行等公司工作。他持有伦敦卡斯商学院的量化金融硕士学位以及哥本哈根大学的经济学本科学位。Peter 是量化金融会议上另类数据和人工智能方面的知名演讲者，并在一些世界顶级学术机构，包括伦敦商学院、纽约大学库兰数学研究所和伦敦帝国学院，发表演讲。

Francesco Lautizi 是 RavenPack 的高级数据科学家，他研究大数据和新闻分析如何重塑金融市场，并提供这些新信息来源如何被金融机构用于投资组合和风险管理目的的见解。他持有罗马托尔维加塔大学的经济学和金融学博士学位，他在那里研究了估计误差对大规模投资组合表现的影响。他曾在 EIEF 作为访问学生，并在罗马托尔维加塔大学获得了金融学硕士学位。

## 第十章

M. Berkan Sesen，博士，是美国一家重要资产管理公司的量化研究员和投资组合经理。在此之前，他曾在花旗集团担任量化分析师，负责监督一个小团队，负责构建/维护用于辅助算法交易和电子市场做市的统计模型。他还共同领导了花旗集团量化分析部门的全球数据分析工作组。

Berkan 拥有牛津大学人工智能博士学位，专攻机器学习和统计学。他还在牛津大学获得了生物医学工程学硕士学位，成绩优异。

Yazann Romahi，博士，特许金融分析师（CFA），董事总经理，是一家美国大型资产管理公司的首席投资官，专注于发展公司的因子式特许经营业务，涵盖替代贝塔和战略性贝塔。 在此之前，他是研究和量化策略主管，负责建立反映全球多资产解决方案投资组合的广泛资产配置的量化模型。 Yazann 曾在剑桥大学金融研究中心担任研究分析师，并为多家金融机构提供咨询服务，包括先锋资产管理、普华永道和汇丰银行。 Yazann 在剑桥大学获得计算金融/人工智能博士学位，并持有特许金融分析师资格。

Victor Li，博士，特许金融分析师（CFA），执行董事，是一家美国大型资产管理公司的股权和替代性贝塔研究负责人兼投资组合经理。 Victor 的主要职责包括管理研究议程，以及为量化贝塔产品套件开发模型和投资组合管理。 Victor 毕业于伦敦帝国理工学院，获得通信与信号处理博士学位，并曾担任全职研究助理。 Victor 在曼彻斯特大学获得了通信工程硕士学位，并且是特许金融分析师。

特许持有人。

## 第十一章

Joel Guglietta 是 Graticule Asset Management 在香港的宏观量化投资组合经理，使用机器学习算法管理多元资产对冲基金。 在此之前，Joel 是亚洲和澳大利亚的对冲基金和投资银行的宏观量化策略师和投资组合经理（Brevan Howard、BTIM、汇丰银行）。

超过 12 年的工作经验。 他的专长是使用各种技术进行资产配置、投资组合构建和管理的量化模型，包括机器学习技术和遗传算法。 Joel 目前是 GREQAM（由法国国家科学研究中心、巴黎高等社会科学研究院和中央理工学院共同管理的研究单位）的博士候选人。 他曾是亚洲许多深度学习和机器学习活动的演讲者。

## 第十二章

Gordon Ritter 于 2007 年在哈佛大学完成了他的数学物理博士学位，他的发表作品涵盖了量子计算、量子场论、微分几何和抽象代数等领域。在哈佛之前，他在芝加哥大学获得了数学荣誉学士学位。Gordon 是 GSA Capital 的高级投资组合经理，领导着一个团队在不同地理区域和资产类别上交易一系列系统的绝对回报策略。GSA Capital 四次赢得了 EuroHedge 奖项中的股票市场中性和定量策略类别，还获得了众多其他奖项，包括长期表现类别。在加入 GSA 之前，Gordon 曾是 Highbridge Capital 的副总裁，是该公司统计套利团队的核心成员，尽管该团队不到 20 人，但负责的交易额度数十亿美元，涉及股票、期货和期权，与传统资产类别的相关性很低。除了在工业界的职位外，Gordon 还在罗格斯大学统计系教授包括投资组合管理、计量经济学、连续时间金融和市场微观结构等课程，还在巴鲁克学院（CUNY）和纽约大学的 MFE 项目中教授课程（这两所学校的 MFE 项目均排名前五）。Gordon 在*Risk*等顶级从业者期刊和*European Journal of Operational Research*等学术期刊上发表了原创作品。他是主要行业会议上备受追捧的演讲嘉宾。

## 第十三章

Miquel Noguer Alonso 是一位金融市场从业者，在资产管理领域拥有超过 20 年的经验。他目前是全球 AI 开发部门的主管。

（大数据人工智能在金融公司）以及 IEF 的创新和技术主管。他曾担任瑞士联合银行 AG（UBS AG）的执行董事。他已经是欧洲投资委员会的成员已有 10 年。他曾在 Andbank 担任首席投资官和 CIO，从 2000 年到 2006 年。他在 KPMG 开始了他的职业生涯。Miquel 是哥伦比亚大学的兼职教授，教授资产配置、金融中的大数据和金融科技。他还是 ESADE 的教授，教授对冲基金、金融中的大数据和金融科技。他于 2017 年在伦敦商学院教授了第一门金融科技和大数据课程。Miquel 于 1993 年在 ESADE 获得 MBA 学位和工商管理学位。2010 年，他以优异成绩（UNED - 西班牙马德里）获得量化金融博士学位。2012 年，他在哥伦比亚商学院完成了博士后研究。在博士期间，他与瑞士弗里堡大学的数学系合作。他还拥有 2000 年的欧洲金融分析师（CEFA）资格。

他的学术合作包括 2013 年在哥伦比亚大学金融与经济学系的访问学者，2010 年在弗里堡大学数学系，以及在印第安纳大学、ESADE 和 CAIA 的演讲，还有包括 2017 年和 2010 年的 Quant Summit USA 等行业研讨会。

Gilberto Batres-Estrada 是瑞典斯德哥尔摩 Webstep 公司的高级数据科学家，他在那里担任顾问，为 Webstep 的客户开发机器学习和深度学习算法。他在计算机视觉、目标检测、自然语言处理和金融领域开发算法，为金融、电信、交通等行业的客户提供服务。在此之前，Gilberto 曾在瑞典哥德堡的 Assa Bay Capital 公司开发交易算法。他有超过

在瑞典半官方机构工作的 IT 经验已达九年。

Gilberto 拥有瑞典斯德哥尔摩大学理论物理学硕士学位和瑞典皇家理工学院工程学硕士学位，专攻应用数学和统计学。

Aymeric Moulin 是哥伦比亚大学 IEOR 系的研究生，在那里主修运筹学。他在法国的预备班学习理论数学和物理，并在 CentraleSupélec 工程学院获得理学学士学位，即将获得硕士学位。

过去几年，他一直专注于将深度学习和强化学习应用于金融市场。他目前在 JP Morgan 全球股票部门担任实习生。
